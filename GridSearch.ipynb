{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BFwl_iaUj_I"
      },
      "source": [
        "# TAREA 1: Métodos de aprendizaje conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N--sRVFc6JpH"
      },
      "source": [
        "NOMBRES:\n",
        "\n",
        "Santiago Gómez Arias\n",
        "\n",
        "Miguel Castro\n",
        "\n",
        "Juan Carlos Castillo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac79xDFmUj_K"
      },
      "source": [
        "## 1. Preguntas conceptuales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK8NhErzUj_K"
      },
      "source": [
        "### 1.1. ¿Si un algoritmo `gradient boosting ensemble` muestra `sobreajuste`, ¿debería aumentar o disminuir la tasa de aprendizaje? Argumente su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AULA7UykUj_K"
      },
      "source": [
        "**Respuesta: Se debería bajar la tasa de aprendizaje, ya que una tasa de aprendizaje más baja reduce la velocidad con la que el modelo se ajusta a los datos de entrenamiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUG8PyfkUj_L"
      },
      "source": [
        "### 1.2. Si ha entrenado 5 `modelos diferentes` de clasificación con exactamente los mismos datos de entrenamiento y todos ellos alcanzan una exactitud (`accuracy`) del $95\\%$, ¿existe alguna posibilidad de que pueda combinar estos modelos para obtener mejores resultados? Si es así, ¿cómo? Si no, ¿por qué?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nm-EGZVUj_L"
      },
      "source": [
        "**Respuesta: Sí es posible, ya que estadísticamente es más probable obtener una elección correcta al usar varios votantes que solo uno.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNVNY1S8Uj_L"
      },
      "source": [
        "### 1.3. Suponga que en el escenario de la pregunta `1.2` se combinan los `5` clasificadores base mediante el método de `voto mayoritario duro`. Calcule el error del clasificador conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3RhUZ9_Qjeh"
      },
      "source": [
        " Como el accuracy de los clasificadores es del 95%, los errores son del 5%. Luego como usaremos el voto mayoritario duro y tenemos 5 clasificadores, aquí obtendremos un error cuando obtengamos un error en tres o más casos. Por lo que la probabilidad de equivocarse sería\n",
        "\n",
        " $ E = \\displaystyle\\sum_{k=3}^5 \\binom{5}{k}0.05^k(1-0.05)^{5-k}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWjWl5J4QTbh",
        "outputId": "03f4572e-be8d-4a4a-a1ab-c7cca914ddcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.116 %\n"
          ]
        }
      ],
      "source": [
        "# Calculamos la probabilidad de error del ensemble\n",
        "import scipy.stats as stats\n",
        "error_ensemble = sum(stats.binom.pmf(k, 5, 0.05) for k in range(3, 5 + 1))\n",
        "print(round(error_ensemble,5)*100,\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsw6QuciUj_L"
      },
      "source": [
        "**Respuesta: El error es de 0.116%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCYR8LssUj_M"
      },
      "source": [
        "### 1.4. ¿Si un algoritmo `Adaboost` muestra `subajuste`, ¿qué hiperparámetros debería ajustar y cómo? Argumente su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2hYelia6JpW"
      },
      "source": [
        "Los hiperparámetros relacionados con el Adaboost son el estimador, la tasa de aprendizaje y el número de estimadores.  Sin embargo, el estimador no participa directamente en que tanto un modelo aprende de sus datos de entrenamiento. En este caso los parámetros que se deberían ajustar con la tasa de aprendizaje y el número de estimadores. La tasa de aprendizaje se debe incrementar para que los pasos con el que se cambian los parámetros del modelos no sean tan pequeños y aprenda un poco más rápido; y el número de estimadores también debe incrementarse para que haya una mayor de cantidad de pasos para que se ajuste más a los datos. En otra palabras estaríamos graduando el número de pasos y la longitud de esos pasos para llegar al ajuste deseado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omajRCCaUj_M"
      },
      "source": [
        "## 2. Ejercicio(s) práctico(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfoMVYN5Uj_M"
      },
      "source": [
        "El conjunto de datos `mnist_784`, contiene 70.000 pequeñas imágenes de dígitos escritos a mano por estudiantes de secundaria y empleados de la Oficina del Censo de EE.UU. Es posible acceder a este dataset medinte las siguientes instrucciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "Sbrs4g8HUj_M",
        "outputId": "355c78ee-1c17-4665-80f2-909ad1d8b078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 3.95 s\n",
            "Wall time: 9.42 s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2    3    4    5    6    7    8    9    ...  774  775  776  \\\n",
              "0        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "2        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "3        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "4        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "69995    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "69996    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "69997    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "69998    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "69999    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
              "\n",
              "       777  778  779  780  781  782  783  \n",
              "0        0    0    0    0    0    0    0  \n",
              "1        0    0    0    0    0    0    0  \n",
              "2        0    0    0    0    0    0    0  \n",
              "3        0    0    0    0    0    0    0  \n",
              "4        0    0    0    0    0    0    0  \n",
              "...    ...  ...  ...  ...  ...  ...  ...  \n",
              "69995    0    0    0    0    0    0    0  \n",
              "69996    0    0    0    0    0    0    0  \n",
              "69997    0    0    0    0    0    0    0  \n",
              "69998    0    0    0    0    0    0    0  \n",
              "69999    0    0    0    0    0    0    0  \n",
              "\n",
              "[70000 rows x 784 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', as_frame=False)\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "pd.DataFrame(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "3_QSRobfUj_O",
        "outputId": "e49f9f08-02b4-45b1-f8da-3a2110afd66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La etiqueta de esta imagen es:  3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##Visualización\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_digit(image_data):\n",
        "    image = image_data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "print(\"La etiqueta de esta imagen es: \", y[12])\n",
        "plot_digit(X[12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFqGst5s6Jpe"
      },
      "source": [
        "NMF (Non-negative Matrix Factorization) se aplica a matrices de datos que contienen solo `valores no negativos`.\n",
        "\n",
        "De manera similar a `PCA`, podemos realizar una `reducción dimensional` y obtener una entrada dimensional reducida utilizando `NMF`. Notamos que obtenemos imágenes un poco `menos ruidosas` en comparación con el resultado de PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCLePEbb6Jpf"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA, NMF\n",
        "\n",
        "def reducedInputPCA(X:   pd.DataFrame,\n",
        "                    nPC: int\n",
        "                    ):\n",
        "    pca = PCA(n_components = nPC)        ## instanciando\n",
        "    X_pca = pca.fit_transform(X)         ## \"entrenando\"\n",
        "    return pca.inverse_transform(X_pca)\n",
        "\n",
        "\n",
        "def reducedInputNMF(X,n):\n",
        "    nmf = NMF(n_components = n, init='random', random_state=0)      #\n",
        "    X_nmf = nmf.fit_transform(X)                                  #\n",
        "    return nmf.inverse_transform(X_nmf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsEuiNydUj_O"
      },
      "source": [
        "- 2.1 Escale todas las `784` variables con el método `min-max`; pero usando en máximo y el mínimo globales, en lugar de los de cada columna. Vrase el `ejercicio 0312` del capítulo 5, unidad 8 (`ensemble algorithms`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGWO-_mlamzL"
      },
      "outputs": [],
      "source": [
        "X_min = X.min()\n",
        "X_max = X.max()\n",
        "X_range = X_max - X_min\n",
        "X = (X - X_min)/X_range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IHEztfO6Jpg",
        "outputId": "1b16ea26-df3d-4743-f97d-9b4deb1711ae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#X_reduced_1 = reducedInputNMF(X,195)\n",
        "#plot_digit(X_reduced_1[12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38Y_G2Vv6Jph",
        "outputId": "3aa1f4d7-e4fa-4b88-ce8b-82c6892371d6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X_reduced_2 = reducedInputNMF(X,48)\n",
        "plot_digit(X_reduced_2[12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGxXb1DnUj_O"
      },
      "source": [
        "- 2.2 Divida los datos en un conjunto de entrenamiento y un conjunto de prueba (utilizar $60.000$ registros para el entrenamiento y $10.000$ para prueba). Luego, entrene los siguientes clasificadores optimizando los `hiperparámetros` más representativos (excepto los de regularización) mediante la `validación cruzada `:\n",
        "\n",
        "  - clasificador SVM.\n",
        "  - Regresión logística\n",
        "  - Naive Bayes\n",
        "  - K-vecinos\n",
        "  - Árbol de decisión\n",
        "\n",
        "  Compare los rendimientos de cada uno de ellos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDy4_lCMlWZb"
      },
      "source": [
        "Respuesta: Dividiendo los datos en entrenamiento y test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPTl9ao9cclp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 1/7, random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLvlNsAl6Jpk"
      },
      "outputs": [],
      "source": [
        "#X_reduced_1_train, X_reduced_1_test, Y_reduced_1_train, Y_reduced_1_test = train_test_split(X_reduced_1, y, test_size = 1/7, random_state=1234)\n",
        "X_reduced_2_train, X_reduced_2_test, Y_reduced_2_train, Y_reduced_2_test = train_test_split(X_reduced_2, y, test_size = 1/7, random_state=1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lB0-vmZrD32"
      },
      "source": [
        "Creando modelo 1: Regresión logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SUBX3lS-rO-p",
        "outputId": "6db457ee-107a-4dae-f1ea-719bef8426f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor penalty es: None\n",
            "El mejor número de máximas iteraciones es: 100\n",
            "CPU times: total: 2min\n",
            "Wall time: 1min 14s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.linear_model import LogisticRegression     #se importa cada clasificador individual\n",
        "\n",
        "penalty = [None]#['l1', 'l2']\n",
        "max_iter = [50, 100, 200]\n",
        "#No se usa aquí parámetro de regularización C\n",
        "parameters_lr = {'penalty': penalty, 'max_iter': max_iter}\n",
        "\n",
        "\n",
        "gridCV_lr = GridSearchCV( LogisticRegression(random_state = 12345), parameters_lr, n_jobs = -1)\n",
        "gridCV_lr.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_penalty = gridCV_lr.best_params_['penalty']\n",
        "best_max_iter  = gridCV_lr.best_params_['max_iter']\n",
        "\n",
        "\n",
        "print(\"El mejor penalty es: \" + str(best_penalty))\n",
        "print(\"El mejor número de máximas iteraciones es: \" + str(best_max_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3O8y4CQj0B8",
        "outputId": "f6c4c2d7-6ebf-45e4-c566-90e8ab51081e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor accuracy del LR : 0.901\n"
          ]
        }
      ],
      "source": [
        "LR_best = LogisticRegression(penalty=best_penalty, max_iter=best_max_iter, random_state = 12345)\n",
        "\n",
        "LR_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_lr = LR_best.predict(X_reduced_2_test)\n",
        "print( \"El mejor accuracy del LR : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_lr),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg8LcuTCrEBx"
      },
      "source": [
        "Creando modelo 2: Naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp0xqiuAr3YO",
        "outputId": "aac920cb-9f97-40bd-8097-854e1873de58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor var_smoothing es: 0.1\n",
            "CPU times: total: 1.33 s\n",
            "Wall time: 27.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.naive_bayes  import GaussianNB\n",
        "var_smoothing= [1e-11, 1e-9, 1e-7, 1e-5, 1e-3, 1e-1, 1, 10]\n",
        "parameters_nb = {'var_smoothing': var_smoothing}\n",
        "\n",
        "\n",
        "gridCV_nb = GridSearchCV(GaussianNB(), parameters_nb, n_jobs = -1)\n",
        "gridCV_nb.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_var_smoothing = gridCV_nb.best_params_['var_smoothing']\n",
        "\n",
        "print(\"El mejor var_smoothing es: \" + str(best_var_smoothing))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6_qzcvSpOr6",
        "outputId": "8fd81bd1-c135-4a2f-c1b1-996bd4a4b5bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor accuracy del NB : 0.803\n"
          ]
        }
      ],
      "source": [
        "NB_best = GaussianNB(var_smoothing=best_var_smoothing)\n",
        "\n",
        "NB_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_nb = NB_best.predict(X_reduced_2_test)\n",
        "print( \"El mejor accuracy del NB : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_nb),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtprX76orEfh"
      },
      "source": [
        "Creando modelo 3: K-vecinos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YtNQ1IHr2zw",
        "outputId": "4391ef80-caad-414d-dc34-675b9f248812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor n_neighbors es: 5\n",
            "El mejor p es: 2\n",
            "El mejor weights es: distance\n",
            "CPU times: total: 547 ms\n",
            "Wall time: 1min 27s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.neighbors    import KNeighborsClassifier   #se importa cada clasificador individual\n",
        "n_neighbors = [3, 5, 7]# Mejor número impar [3, 5, 7, 9]\n",
        "p = [2]#[1, 2, 3]\n",
        "weights = ['uniform', 'distance']#\n",
        "parameters_knn = {'n_neighbors': n_neighbors, 'p': p, 'weights': weights}\n",
        "\n",
        "\n",
        "gridCV_knn = GridSearchCV(KNeighborsClassifier(), parameters_knn, n_jobs = -1)\n",
        "gridCV_knn.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_n_neighbors = gridCV_knn.best_params_['n_neighbors']\n",
        "best_p = gridCV_knn.best_params_['p']\n",
        "best_weights  = gridCV_knn.best_params_['weights']\n",
        "\n",
        "\n",
        "print(\"El mejor n_neighbors es: \" + str(best_n_neighbors))\n",
        "print(\"El mejor p es: \" + str(best_p))\n",
        "print(\"El mejor weights es: \" + str(best_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lRWG2OkzlFs",
        "outputId": "13191b41-ce90-46fe-f1cd-e19d4b2d9c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor accuracy del KNN : 0.975\n"
          ]
        }
      ],
      "source": [
        "KNN_best = KNeighborsClassifier(n_neighbors=best_n_neighbors, p=best_p, weights=best_weights)\n",
        "\n",
        "KNN_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_knn = KNN_best.predict(X_reduced_2_test)\n",
        "print( \"El mejor accuracy del KNN : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_knn),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "898fBmNrluN-"
      },
      "source": [
        "Creando modelo 4: Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnL47ibXlelE",
        "outputId": "4fadf68e-e0c5-491d-97cc-055b3272abb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La mejor max_depth del árbol: 11\n",
            "El mejor min_samples_leaf del árbol: 2\n",
            "El mejor max_leaf_nodes del árbol: 53\n",
            "CPU times: total: 37.9 s\n",
            "Wall time: 28min 34s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.tree import  DecisionTreeClassifier\n",
        "depth_grid = np.arange(1,22,5)\n",
        "min_samples_leaf_grid = np.arange(2,23,5) #\n",
        "max_leaf_nodes_grid = np.arange(23,54,5)#\n",
        "parameters_dt = {'max_depth':depth_grid, 'min_samples_leaf':min_samples_leaf_grid, 'max_leaf_nodes':max_leaf_nodes_grid}\n",
        "\n",
        "\n",
        "gridCV_dt = GridSearchCV(DecisionTreeClassifier(random_state = 12345), parameters_dt, n_jobs = -1)\n",
        "gridCV_dt.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_depth = gridCV_dt.best_params_['max_depth']\n",
        "best_min_samples_leaf = gridCV_dt.best_params_['min_samples_leaf']\n",
        "best_max_leaf_nodes = gridCV_dt.best_params_['max_leaf_nodes']\n",
        "\n",
        "\n",
        "print(\"La mejor max_depth del árbol: \" + str(best_depth))\n",
        "print(\"El mejor min_samples_leaf del árbol: \" + str(best_min_samples_leaf))\n",
        "print(\"El mejor max_leaf_nodes del árbol: \" + str(best_max_leaf_nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5QxRQmbAWpx",
        "outputId": "da1ca05c-6ba5-4e6c-e992-a6939026608f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La mejor accuracy del árbol : 0.786\n"
          ]
        }
      ],
      "source": [
        "DT_best = DecisionTreeClassifier(max_depth=best_depth, min_samples_leaf=best_min_samples_leaf, max_leaf_nodes=best_max_leaf_nodes, random_state = 12345)\n",
        "\n",
        "DT_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_dt = DT_best.predict(X_reduced_2_test)\n",
        "print( \"La mejor accuracy del árbol : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_dt),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLquWkPQ6Jps"
      },
      "source": [
        "Creando modelo 5: SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnpDFKZJ6Jps",
        "outputId": "e449cf9a-11d3-4bcf-9377-c7bb9bea3b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor degree es: 2\n",
            "El mejor kernel es: rbf\n",
            "CPU times: total: 1min 57s\n",
            "Wall time: 27min 56s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.svm  import SVC\n",
        "\n",
        "degree = [2,3]#\n",
        "kernel =  ['rbf','poly']#\n",
        "#No se usa aquí parámetro de regularización C\n",
        "parameters_svm = {'degree': degree, 'kernel': kernel}\n",
        "\n",
        "\n",
        "gridCV_svm = GridSearchCV(SVC(gamma='scale', random_state = 12345), parameters_svm, n_jobs = -1)\n",
        "gridCV_svm.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_degree = gridCV_svm.best_params_['degree']\n",
        "best_kernel  = gridCV_svm.best_params_['kernel']\n",
        "\n",
        "\n",
        "print(\"El mejor degree es: \" + str(best_degree))\n",
        "print(\"El mejor kernel es: \" + str(best_kernel))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq6pSqyS6Jpt",
        "outputId": "7d5f32c2-59fa-4c93-cdec-abb4d96c963b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor accuracy del SVM : 0.974\n"
          ]
        }
      ],
      "source": [
        "SVM_best = SVC(degree=best_degree, kernel=best_kernel, gamma='scale', probability= True,  random_state = 12345)# gamma = 'auto',\n",
        "\n",
        "SVM_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_svm = SVM_best.predict(X_reduced_2_test)\n",
        "print( \"El mejor accuracy del SVM : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_svm),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekdw0F8NUj_O"
      },
      "source": [
        "- 2.3 Utilizando la combinación de hiperparámetroas más óptima para cada uno de los modelos anteriores, construya un clasificador por `voto mayoritario` tanto tipo `hard` como tipo `soft`. Elejia el más `eficiente` de los dos métodos y compare su rendimientro contra el mejor clasificador undividual del numeral anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOo2Too3fCS7",
        "outputId": "ba89941f-f9ef-4119-bccb-bd61e561b097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97       948\n",
            "           1       0.96      0.99      0.97      1147\n",
            "           2       0.95      0.95      0.95      1026\n",
            "           3       0.93      0.93      0.93      1009\n",
            "           4       0.95      0.96      0.96       991\n",
            "           5       0.95      0.92      0.93       914\n",
            "           6       0.96      0.97      0.96       967\n",
            "           7       0.95      0.95      0.95      1037\n",
            "           8       0.97      0.92      0.94       966\n",
            "           9       0.94      0.92      0.93       995\n",
            "\n",
            "    accuracy                           0.95     10000\n",
            "   macro avg       0.95      0.95      0.95     10000\n",
            "weighted avg       0.95      0.95      0.95     10000\n",
            "\n",
            "CPU times: total: 1min 14s\n",
            "Wall time: 11min 41s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import VotingClassifier             # Se importa clasificador por votación\n",
        "\n",
        "myVotingEnsemble_hard=VotingClassifier(estimators=[('SVM',SVM_best), ('LR',LR_best), ('nb',NB_best), ('knn',KNN_best),  ('dt',DT_best)],voting='hard', verbose = True, n_jobs = -1)\n",
        "myVotingEnsemble_hard.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "print(metrics.classification_report(Y_reduced_2_test, myVotingEnsemble_hard.predict(X_reduced_2_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWTsiSqNsrqW",
        "outputId": "00e5b85b-6ff2-4742-ca88-7b197f896d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       948\n",
            "           1       0.96      0.99      0.97      1147\n",
            "           2       0.96      0.94      0.95      1026\n",
            "           3       0.95      0.94      0.94      1009\n",
            "           4       0.97      0.96      0.96       991\n",
            "           5       0.96      0.93      0.95       914\n",
            "           6       0.95      0.98      0.96       967\n",
            "           7       0.95      0.96      0.96      1037\n",
            "           8       0.96      0.95      0.96       966\n",
            "           9       0.92      0.94      0.93       995\n",
            "\n",
            "    accuracy                           0.96     10000\n",
            "   macro avg       0.96      0.96      0.96     10000\n",
            "weighted avg       0.96      0.96      0.96     10000\n",
            "\n",
            "CPU times: total: 1min 13s\n",
            "Wall time: 11min 34s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import VotingClassifier             # Se importa clasificador por votación\n",
        "\n",
        "myVotingEnsemble_soft=VotingClassifier(estimators=[('SVM',SVM_best), ('LR',LR_best), ('nb',NB_best), ('knn',KNN_best),  ('dt',DT_best)],voting='soft', verbose = True, n_jobs = -1)\n",
        "myVotingEnsemble_soft.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "print(metrics.classification_report(Y_reduced_2_test, myVotingEnsemble_soft.predict(X_reduced_2_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IyGdCT56Jpv"
      },
      "source": [
        "El método de votación mejor es el suave \"soft\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etGp76uxUj_O"
      },
      "source": [
        "- 2.4 Utilice el `mejor modelo individual` hallado en el numeral `2.2` y contruya un clasificador con el método `Bagging`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI2qNxS_6Jpv",
        "outputId": "9eaf4eaf-a060-4742-babc-ef879c54b794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor n_estimators es: 5\n",
            "CPU times: total: 2.61 s\n",
            "Wall time: 22min 16s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "n_estimators_bag= [5, 10, 50]#\n",
        "parameters_bagging = {'n_estimators': n_estimators_bag}\n",
        "\n",
        "gridCV_bagging= GridSearchCV(BaggingClassifier(KNN_best), parameters_bagging, n_jobs = -1)\n",
        "gridCV_bagging.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_n_estimators_bag = gridCV_bagging.best_params_['n_estimators']\n",
        "\n",
        "\n",
        "print(\"El mejor n_estimators es: \" + str(best_n_estimators_bag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4Qn3fQc6Jpw",
        "outputId": "6d0eaef2-a243-4edf-cd63-6737c15727c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor accuracy del bagging : 0.974\n"
          ]
        }
      ],
      "source": [
        "bagging_best = BaggingClassifier(KNN_best, n_estimators=best_n_estimators_bag,  n_jobs=-1)\n",
        "\n",
        "bagging_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_bagging = bagging_best.predict(X_reduced_2_test)\n",
        "print( \"El mejor accuracy del bagging : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_bagging ),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzgxR8I5Uj_P"
      },
      "source": [
        "- 2.5 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `bosque aleatorio` y utilice la validación cruzada afinar solamente un hiperparámetro: `n_estimators`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiZXrHdC6Jpx",
        "outputId": "0ae8a15a-998f-410a-99d1-de8589f4477c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor n_estimators es: 500\n",
            "CPU times: total: 5min 57s\n",
            "Wall time: 11min 22s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "n_estimators_rfc= [10, 50, 100, 500]#\n",
        "parameters_rfc = {'n_estimators': n_estimators_rfc}\n",
        "\n",
        "gridCV_rfc= GridSearchCV(RandomForestClassifier(max_depth=best_depth, min_samples_leaf=best_min_samples_leaf, max_leaf_nodes=best_max_leaf_nodes, random_state = 12345, class_weight = \"balanced\"), parameters_rfc, n_jobs = -1)\n",
        "gridCV_rfc.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_n_estimators_rfc = gridCV_rfc.best_params_['n_estimators']\n",
        "\n",
        "\n",
        "print(\"El mejor n_estimators es: \" + str(best_n_estimators_rfc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pxZKaEl6Jpx",
        "outputId": "1992df5e-213a-46b9-c8a3-56a60a5add19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest accuracy : 0.893\n",
            "CPU times: total: 5min 57s\n",
            "Wall time: 5min 57s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Clasificación por Random Forest.\n",
        "RFC_best = RandomForestClassifier(n_estimators=best_n_estimators_rfc , max_depth=best_depth, min_samples_leaf=best_min_samples_leaf, max_leaf_nodes=best_max_leaf_nodes, random_state = 12345, class_weight = \"balanced\")\n",
        "RFC_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_rfc = RFC_best.predict(X_reduced_2_test)\n",
        "print( \"Random Forest accuracy : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_rfc),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzN18cDTUj_P"
      },
      "source": [
        "- 2.6 Utilice el `mejor modelo individual` hallado en el numeral `2.2` y contruya un clasificador con el método `AdaBoost`y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNnjSB-16Jpy",
        "outputId": "c09ea331-6841-4345-aec8-37c3e8ee71bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor n_estimators es: 10\n",
            "El mejor learning_rate es: 0.1\n",
            "CPU times: total: 20min 19s\n",
            "Wall time: 17min 8s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "n_estimators_ab= [10, 20]#, 50, 100\n",
        "learning_rate_ab= [1, 1e-1]#\n",
        "\n",
        "parameters_adaboost = {'n_estimators': n_estimators_ab, 'learning_rate':learning_rate_ab}\n",
        "\n",
        "gridCV_ab = GridSearchCV(AdaBoostClassifier(LR_best,random_state=123), parameters_adaboost , n_jobs = -1)\n",
        "gridCV_ab.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_n_estimators_ab = gridCV_ab.best_params_['n_estimators']\n",
        "best_learning_rate_ab = gridCV_ab.best_params_['learning_rate']\n",
        "\n",
        "\n",
        "print(\"El mejor n_estimators es: \" + str(best_n_estimators_ab))\n",
        "print(\"El mejor learning_rate es: \" + str(best_learning_rate_ab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5URVF_w6Jpy",
        "outputId": "e1cf0795-79d1-4262-fe72-699da8dfc232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adaboost accuracy : 0.881\n",
            "CPU times: total: 20min 27s\n",
            "Wall time: 1min 31s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Clasificación por adaboost.\n",
        "AdaBoost_best = AdaBoostClassifier(LR_best, random_state=123, n_estimators=best_n_estimators_ab, learning_rate=best_learning_rate_ab)\n",
        "AdaBoost_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_ada = AdaBoost_best.predict(X_reduced_2_test)\n",
        "print( \"Adaboost accuracy : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_ada),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TVGjuyoUj_P"
      },
      "source": [
        "- 2.7 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `GradientBoostingClassifier` y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzvqZAsm6Jpz",
        "outputId": "6823ef33-5f41-4881-eb6a-09480aa9214e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_reduced_1_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32m<timed exec>:8\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'X_reduced_1_train' is not defined"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "n_estimators_gbc= [10]#, 50, 100\n",
        "learning_rate_gbc= [1]#, 1e-1\n",
        "parameters_gbc = {'n_estimators': n_estimators_gbc, 'learning_rate':learning_rate_gbc}\n",
        "\n",
        "gridCV_gbc= GridSearchCV(GradientBoostingClassifier(max_depth=best_depth, min_samples_leaf=best_min_samples_leaf, max_leaf_nodes=best_max_leaf_nodes, random_state = 12345), parameters_gbc, n_jobs = -1)\n",
        "gridCV_gbc.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "#-----------\n",
        "best_n_estimators_gbc = gridCV_gbc.best_params_['n_estimators']\n",
        "best_learning_rate_gbc = gridCV_gbc.best_params_['learning_rate']\n",
        "\n",
        "\n",
        "print(\"El mejor n_estimators es: \" + str(best_n_estimators_gbc))\n",
        "print(\"El mejor learning rate es: \" + str(best_learning_rate_gbc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pXtVsH16Jp0"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Clasificación por Gradient Boosting.\n",
        "GBC_best = GradientBoostingClassifier(n_estimators=best_n_estimators_gbc, learning_rate=best_learning_rate_gbc, max_depth=best_depth, min_samples_leaf=best_min_samples_leaf, max_leaf_nodes=best_max_leaf_nodes, random_state = 12345)\n",
        "GBC_best.fit(X_reduced_2_train, Y_reduced_2_train)\n",
        "Y_pred_gbc = GBC_best.predict(X_reduced_2_test)\n",
        "print( \"Gradient Boosting accuracy : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test,Y_pred_gbc),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8cbeXsUj_P"
      },
      "source": [
        "- 2.8 Utilizando los hiperparámetros del mejor `árbol de decisión` construido en el numeral `2.2`, entrene un `XGBClassifier` y utilice la validación cruzada afinar solamente dos hiperparámetros: `n_estimators` y `learning_rate`. Compare su rendimiento con los modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3SjofjK6Jp2",
        "outputId": "56a1882d-01e8-4687-eabe-0047401f597c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor n_estimators es: 50\n",
            "El mejor learning rate es: 1\n",
            "CPU times: total: 18min 16s\n",
            "Wall time: 43min 32s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "n_estimators_XGBC= [10, 20, 50]\n",
        "learning_rate_XGBC= [1, 1e-1]\n",
        "parameters_XGBC = {'n_estimators': n_estimators_XGBC, 'learning_rate':learning_rate_XGBC}\n",
        "\n",
        "Y_reduced_2_train_int = Y_reduced_2_train.astype(int)\n",
        "\n",
        "gridCV_XGBC= GridSearchCV(XGBClassifier(max_depth=best_depth, min_samples_leaf=best_min_samples_leaf, max_leaf_nodes=best_max_leaf_nodes, random_state = 12345), parameters_XGBC, n_jobs = -1)\n",
        "gridCV_XGBC.fit(X_reduced_2_train, Y_reduced_2_train_int)\n",
        "#-----------\n",
        "best_n_estimators_XGBC = gridCV_XGBC.best_params_['n_estimators']\n",
        "best_learning_rate_XGBC = gridCV_XGBC.best_params_['learning_rate']\n",
        "\n",
        "\n",
        "print(\"El mejor n_estimators es: \" + str(best_n_estimators_XGBC))\n",
        "print(\"El mejor learning rate es: \" + str(best_learning_rate_XGBC))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZHFGFW36Jp3",
        "outputId": "cea71e75-a7b6-4496-f14f-a91ef80f4c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost accuracy : 0.967\n",
            "CPU times: total: 17min 48s\n",
            "Wall time: 1min 14s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Clasificación por XGB.\n",
        "XGBC_best = XGBClassifier(n_estimators=best_n_estimators_XGBC, learning_rate=best_learning_rate_XGBC, max_depth=best_depth, min_samples_leaf=best_min_samples_leaf, max_leaf_nodes=best_max_leaf_nodes, random_state = 12345)\n",
        "XGBC_best.fit(X_reduced_2_train, Y_reduced_2_train_int)\n",
        "Y_pred_XGBC = XGBC_best.predict(X_reduced_2_test)\n",
        "print( \"XGBoost accuracy : \" + str(np.round(metrics.accuracy_score(Y_reduced_2_test.astype(int),Y_pred_XGBC),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o5dBFMnUj_P"
      },
      "source": [
        "- 2.9 Elija `el mejor clasificador` de entre todos los entrenados previamente y argumente su respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conkUHAp6Jp9"
      },
      "source": [
        "Al evaluar varios de los métodos que se usaron aquí utilizando los datos en distintas formas: por ejemplo en su forma pura (784 features), reducido 4 veces (196 features) y reducido 16 veces (49 features), los tiempos de ejecución y la precisión que se tuvo para cada uno fue muy variada, demórandose el ajuste desde un pocos segundos hasta llegar a decenas de minutos o incluso a veces cientos de minutos. Por ejemplo el clasificador con gradient boosting se demoró demasiado y fue el único método que no se alcanzó a comparar debido a su enorme tiempo de ejecución en el entrenamiento. Con todo esto en cuenta el mejor clasificador para este ejercicio fue el KNN ya que obtuvo un accuracy bastante bueno (97,5%) incluso para los datos reducidos 16 veces, además de que se pudo entrenar en un tiempo bastante corto.\n",
        "\n",
        "Es muy probable que con modelos de votación más complejos, votación, bagging o boosting, se puedan obtener mejores accuracy con los hiperparámetros correctos, ya que aquí por cuestión de tiempo no se pudo probar muchos distintos hiperparámetros usando el GridSearchCV, y aún así se consiguieron buenos accuracy. Pero para este problema en específico el accuracy del clasificador KNN está tan cerca al 100% y es tan rápido, que lo elijo para este problema como el mejor clasificador por su practicidad."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "SFC_V2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}