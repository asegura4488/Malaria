{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421769cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanos (negativos): 125 | Nosanos (positivos): 125\n",
      "[LOAD] sano_000.png (y=0) superpix=526\n",
      "[LOAD] sano_002.png (y=0) superpix=586\n",
      "[LOAD] sano_005.png (y=0) superpix=558\n",
      "[LOAD] sano_009.png (y=0) superpix=459\n",
      "[LOAD] sano_010.png (y=0) superpix=612\n",
      "[LOAD] sano_011.png (y=0) superpix=618\n",
      "[LOAD] sano_012.png (y=0) superpix=486\n",
      "[LOAD] sano_013.png (y=0) superpix=610\n",
      "[LOAD] sano_014.png (y=0) superpix=662\n",
      "[LOAD] sano_015.png (y=0) superpix=532\n",
      "[LOAD] sano_016.png (y=0) superpix=641\n",
      "[LOAD] sano_017.png (y=0) superpix=467\n",
      "[LOAD] sano_018.png (y=0) superpix=546\n",
      "[LOAD] sano_019.png (y=0) superpix=613\n",
      "[LOAD] sano_022.png (y=0) superpix=646\n",
      "[LOAD] sano_024.png (y=0) superpix=502\n",
      "[LOAD] sano_025.png (y=0) superpix=453\n",
      "[LOAD] sano_026.png (y=0) superpix=666\n",
      "[LOAD] sano_027.png (y=0) superpix=433\n",
      "[LOAD] sano_028.png (y=0) superpix=436\n",
      "[LOAD] sano_029.png (y=0) superpix=549\n",
      "[LOAD] sano_030.png (y=0) superpix=562\n",
      "[LOAD] sano_031.png (y=0) superpix=584\n",
      "[LOAD] sano_032.png (y=0) superpix=426\n",
      "[LOAD] sano_034.png (y=0) superpix=568\n",
      "[LOAD] sano_035.png (y=0) superpix=562\n",
      "[LOAD] sano_036.png (y=0) superpix=455\n",
      "[LOAD] sano_037.png (y=0) superpix=589\n",
      "[LOAD] sano_040.png (y=0) superpix=442\n",
      "[LOAD] sano_042.png (y=0) superpix=476\n",
      "[LOAD] sano_044.png (y=0) superpix=764\n",
      "[LOAD] sano_045.png (y=0) superpix=658\n",
      "[LOAD] sano_047.png (y=0) superpix=581\n",
      "[LOAD] sano_048.png (y=0) superpix=433\n",
      "[LOAD] sano_049.png (y=0) superpix=590\n",
      "[LOAD] sano_052.png (y=0) superpix=561\n",
      "[LOAD] sano_053.png (y=0) superpix=474\n",
      "[LOAD] sano_057.png (y=0) superpix=584\n",
      "[LOAD] sano_058.png (y=0) superpix=604\n",
      "[LOAD] sano_059.png (y=0) superpix=630\n",
      "[LOAD] sano_060.png (y=0) superpix=594\n",
      "[LOAD] sano_063.png (y=0) superpix=583\n",
      "[LOAD] sano_065.png (y=0) superpix=686\n",
      "[LOAD] sano_066.png (y=0) superpix=522\n",
      "[LOAD] sano_067.png (y=0) superpix=631\n",
      "[LOAD] sano_069.png (y=0) superpix=684\n",
      "[LOAD] sano_071.png (y=0) superpix=590\n",
      "[LOAD] sano_073.png (y=0) superpix=585\n",
      "[LOAD] sano_078.png (y=0) superpix=631\n",
      "[LOAD] sano_079.png (y=0) superpix=578\n",
      "[LOAD] sano_080.png (y=0) superpix=627\n",
      "[LOAD] sano_081.png (y=0) superpix=483\n",
      "[LOAD] sano_083.png (y=0) superpix=623\n",
      "[LOAD] sano_084.png (y=0) superpix=625\n",
      "[LOAD] sano_085.png (y=0) superpix=683\n",
      "[LOAD] sano_086.png (y=0) superpix=610\n",
      "[LOAD] sano_088.png (y=0) superpix=513\n",
      "[LOAD] sano_089.png (y=0) superpix=626\n",
      "[LOAD] sano_091.png (y=0) superpix=551\n",
      "[LOAD] sano_092.png (y=0) superpix=611\n",
      "[LOAD] sano_093.png (y=0) superpix=635\n",
      "[LOAD] sano_095.png (y=0) superpix=588\n",
      "[LOAD] sano_096.png (y=0) superpix=622\n",
      "[LOAD] sano_101.png (y=0) superpix=652\n",
      "[LOAD] sano_102.png (y=0) superpix=519\n",
      "[LOAD] sano_104.png (y=0) superpix=478\n",
      "[LOAD] sano_105.png (y=0) superpix=665\n",
      "[LOAD] sano_106.png (y=0) superpix=411\n",
      "[LOAD] sano_107.png (y=0) superpix=626\n",
      "[LOAD] sano_108.png (y=0) superpix=653\n",
      "[LOAD] sano_110.png (y=0) superpix=635\n",
      "[LOAD] sano_114.png (y=0) superpix=555\n",
      "[LOAD] sano_115.png (y=0) superpix=617\n",
      "[LOAD] sano_116.png (y=0) superpix=658\n",
      "[LOAD] sano_117.png (y=0) superpix=663\n",
      "[LOAD] sano_119.png (y=0) superpix=515\n",
      "[LOAD] sano_120.png (y=0) superpix=627\n",
      "[LOAD] sano_121.png (y=0) superpix=638\n",
      "[LOAD] sano_122.png (y=0) superpix=582\n",
      "[LOAD] sano_123.png (y=0) superpix=683\n",
      "[LOAD] sano_125.png (y=0) superpix=637\n",
      "[LOAD] sano_128.png (y=0) superpix=460\n",
      "[LOAD] sano_132.png (y=0) superpix=588\n",
      "[LOAD] sano_134.png (y=0) superpix=574\n",
      "[LOAD] sano_136.png (y=0) superpix=539\n",
      "[LOAD] sano_138.png (y=0) superpix=500\n",
      "[LOAD] sano_139.png (y=0) superpix=636\n",
      "[LOAD] sano_140.png (y=0) superpix=465\n",
      "[LOAD] sano_141.png (y=0) superpix=570\n",
      "[LOAD] sano_142.png (y=0) superpix=542\n",
      "[LOAD] sano_145.png (y=0) superpix=635\n",
      "[LOAD] sano_146.png (y=0) superpix=594\n",
      "[LOAD] sano_148.png (y=0) superpix=574\n",
      "[LOAD] sano_150.png (y=0) superpix=513\n",
      "[LOAD] sano_152.png (y=0) superpix=603\n",
      "[LOAD] sano_153.png (y=0) superpix=588\n",
      "[LOAD] sano_154.png (y=0) superpix=676\n",
      "[LOAD] sano_156.png (y=0) superpix=610\n",
      "[LOAD] sano_157.png (y=0) superpix=685\n",
      "[LOAD] sano_158.png (y=0) superpix=626\n",
      "[LOAD] sano_160.png (y=0) superpix=486\n",
      "[LOAD] sano_164.png (y=0) superpix=666\n",
      "[LOAD] sano_166.png (y=0) superpix=512\n",
      "[LOAD] sano_168.png (y=0) superpix=661\n",
      "[LOAD] sano_169.png (y=0) superpix=586\n",
      "[LOAD] sano_171.png (y=0) superpix=642\n",
      "[LOAD] sano_177.png (y=0) superpix=582\n",
      "[LOAD] sano_181.png (y=0) superpix=515\n",
      "[LOAD] sano_182.png (y=0) superpix=449\n",
      "[LOAD] sano_188.png (y=0) superpix=483\n",
      "[LOAD] sano_189.png (y=0) superpix=605\n",
      "[LOAD] sano_192.png (y=0) superpix=633\n",
      "[LOAD] sano_194.png (y=0) superpix=492\n",
      "[LOAD] sano_195.png (y=0) superpix=463\n",
      "[LOAD] sano_196.png (y=0) superpix=544\n",
      "[LOAD] sano_197.png (y=0) superpix=565\n",
      "[LOAD] sano_198.png (y=0) superpix=623\n",
      "[LOAD] sano_200.png (y=0) superpix=586\n",
      "[LOAD] sano_201.png (y=0) superpix=498\n",
      "[LOAD] sano_202.png (y=0) superpix=604\n",
      "[LOAD] sano_203.png (y=0) superpix=493\n",
      "[LOAD] sano_206.png (y=0) superpix=662\n",
      "[LOAD] sano_207.png (y=0) superpix=530\n",
      "[LOAD] sano_209.png (y=0) superpix=573\n",
      "[LOAD] sano_210.png (y=0) superpix=501\n",
      "[LOAD] 000_seg_012.png (y=1) superpix=482\n",
      "[LOAD] 001_seg_005.png (y=1) superpix=490\n",
      "[LOAD] 003_seg_003.png (y=1) superpix=594\n",
      "[LOAD] 004_seg_000.png (y=1) superpix=434\n",
      "[LOAD] 004_seg_002.png (y=1) superpix=773\n",
      "[LOAD] 005_seg_021.png (y=1) superpix=566\n",
      "[LOAD] 007_seg_019.png (y=1) superpix=526\n",
      "[LOAD] 011_seg_004.png (y=1) superpix=540\n",
      "[LOAD] 011_seg_016.png (y=1) superpix=529\n",
      "[LOAD] 011_seg_039.png (y=1) superpix=529\n",
      "[LOAD] 013_seg_002.png (y=1) superpix=566\n",
      "[LOAD] 013_seg_014.png (y=1) superpix=547\n",
      "[LOAD] 016_seg_007.png (y=1) superpix=586\n",
      "[LOAD] 018_seg_017.png (y=1) superpix=666\n",
      "[LOAD] 019_seg_003.png (y=1) superpix=575\n",
      "[LOAD] 021_seg_006.png (y=1) superpix=523\n",
      "[LOAD] 021_seg_009.png (y=1) superpix=627\n",
      "[LOAD] 022_seg_005.png (y=1) superpix=515\n",
      "[LOAD] 024_seg_018.png (y=1) superpix=505\n",
      "[LOAD] 028_seg_000.png (y=1) superpix=432\n",
      "[LOAD] 030_seg_000.png (y=1) superpix=547\n",
      "[LOAD] 103_seg_009.png (y=1) superpix=725\n",
      "[LOAD] 103_seg_015.png (y=1) superpix=469\n",
      "[LOAD] 106_seg_011.png (y=1) superpix=468\n",
      "[LOAD] 110_seg_007.png (y=1) superpix=568\n",
      "[LOAD] 111_seg_010.png (y=1) superpix=452\n",
      "[LOAD] 112_seg_070.png (y=1) superpix=535\n",
      "[LOAD] 114_seg_009.png (y=1) superpix=500\n",
      "[LOAD] 114_seg_015.png (y=1) superpix=566\n",
      "[LOAD] 115_seg_006.png (y=1) superpix=568\n",
      "[LOAD] 115_seg_008.png (y=1) superpix=578\n",
      "[LOAD] 121_seg_005.png (y=1) superpix=534\n",
      "[LOAD] 121_seg_012.png (y=1) superpix=592\n",
      "[LOAD] 121_seg_016.png (y=1) superpix=426\n",
      "[LOAD] 121_seg_030.png (y=1) superpix=471\n",
      "[LOAD] 123_seg_000.png (y=1) superpix=606\n",
      "[LOAD] 125_seg_002.png (y=1) superpix=431\n",
      "[LOAD] 125_seg_009.png (y=1) superpix=742\n",
      "[LOAD] 126_seg_024.png (y=1) superpix=610\n",
      "[LOAD] 127_seg_014.png (y=1) superpix=510\n",
      "[LOAD] 128_seg_013.png (y=1) superpix=520\n",
      "[LOAD] 128_seg_016.png (y=1) superpix=479\n",
      "[LOAD] 129_seg_020.png (y=1) superpix=444\n",
      "[LOAD] 132_seg_013.png (y=1) superpix=479\n",
      "[LOAD] 133_seg_000.png (y=1) superpix=492\n",
      "[LOAD] 134_seg_013.png (y=1) superpix=542\n",
      "[LOAD] 135_seg_002.png (y=1) superpix=729\n",
      "[LOAD] 135_seg_003.png (y=1) superpix=755\n",
      "[LOAD] 135_seg_026.png (y=1) superpix=427\n",
      "[LOAD] 138_seg_004.png (y=1) superpix=545\n",
      "[LOAD] 138_seg_017.png (y=1) superpix=492\n",
      "[LOAD] 139_seg_028.png (y=1) superpix=653\n",
      "[LOAD] 142_seg_006.png (y=1) superpix=453\n",
      "[LOAD] 142_seg_036.png (y=1) superpix=469\n",
      "[LOAD] 143_seg_004.png (y=1) superpix=540\n",
      "[LOAD] 143_seg_010.png (y=1) superpix=448\n",
      "[LOAD] 144_seg_006.png (y=1) superpix=450\n",
      "[LOAD] 145_seg_004.png (y=1) superpix=541\n",
      "[LOAD] 145_seg_005.png (y=1) superpix=523\n",
      "[LOAD] 146_seg_011.png (y=1) superpix=448\n",
      "[LOAD] 148_seg_031.png (y=1) superpix=474\n",
      "[LOAD] 150_seg_019.png (y=1) superpix=571\n",
      "[LOAD] 150_seg_025.png (y=1) superpix=450\n",
      "[LOAD] 150_seg_029.png (y=1) superpix=476\n",
      "[LOAD] 152_seg_013.png (y=1) superpix=606\n",
      "[LOAD] 152_seg_016.png (y=1) superpix=735\n",
      "[LOAD] 153_seg_008.png (y=1) superpix=727\n",
      "[LOAD] 153_seg_031.png (y=1) superpix=489\n",
      "[LOAD] 155_seg_022.png (y=1) superpix=480\n",
      "[LOAD] 158_seg_024.png (y=1) superpix=579\n",
      "[LOAD] 159_seg_000.png (y=1) superpix=520\n",
      "[LOAD] 159_seg_024.png (y=1) superpix=487\n",
      "[LOAD] 163_seg_041.png (y=1) superpix=633\n",
      "[LOAD] 165_seg_003.png (y=1) superpix=743\n",
      "[LOAD] 165_seg_023.png (y=1) superpix=770\n",
      "[LOAD] 165_seg_027.png (y=1) superpix=495\n",
      "[LOAD] 167_seg_006.png (y=1) superpix=612\n",
      "[LOAD] 167_seg_008.png (y=1) superpix=441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] 167_seg_012.png (y=1) superpix=666\n",
      "[LOAD] 169_seg_026.png (y=1) superpix=433\n",
      "[LOAD] 169_seg_041.png (y=1) superpix=443\n",
      "[LOAD] 170_seg_013.png (y=1) superpix=531\n",
      "[LOAD] 171_seg_005.png (y=1) superpix=457\n",
      "[LOAD] 171_seg_042.png (y=1) superpix=451\n",
      "[LOAD] 173_seg_002.png (y=1) superpix=521\n",
      "[LOAD] 174_seg_027.png (y=1) superpix=548\n",
      "[LOAD] 175_seg_009.png (y=1) superpix=558\n",
      "[LOAD] 175_seg_030.png (y=1) superpix=484\n",
      "[LOAD] 176_seg_015.png (y=1) superpix=520\n",
      "[LOAD] 176_seg_055.png (y=1) superpix=439\n",
      "[LOAD] 176_seg_075.png (y=1) superpix=434\n",
      "[LOAD] 176_seg_100.png (y=1) superpix=810\n",
      "[LOAD] 207_seg_000.png (y=1) superpix=615\n",
      "[LOAD] 209_seg_001.png (y=1) superpix=542\n",
      "[LOAD] 266_seg_001.png (y=1) superpix=498\n",
      "[LOAD] 285_seg_038.png (y=1) superpix=546\n",
      "[LOAD] 288_seg_011.png (y=1) superpix=616\n",
      "[LOAD] 292_seg_012.png (y=1) superpix=568\n",
      "[LOAD] 295_seg_006.png (y=1) superpix=670\n",
      "[LOAD] 295_seg_008.png (y=1) superpix=597\n",
      "[LOAD] 299_seg_012.png (y=1) superpix=447\n",
      "[LOAD] 300_seg_031.png (y=1) superpix=523\n",
      "[LOAD] 302_seg_005.png (y=1) superpix=465\n",
      "[LOAD] 304_seg_001.png (y=1) superpix=566\n",
      "[LOAD] 305_seg_007.png (y=1) superpix=516\n",
      "[LOAD] 306_seg_001.png (y=1) superpix=526\n",
      "[LOAD] 306_seg_017.png (y=1) superpix=656\n",
      "[LOAD] 308_seg_011.png (y=1) superpix=540\n",
      "[LOAD] 310_seg_004.png (y=1) superpix=502\n",
      "[LOAD] 310_seg_011.png (y=1) superpix=586\n",
      "[LOAD] 311_seg_026.png (y=1) superpix=661\n",
      "[LOAD] 311_seg_027.png (y=1) superpix=615\n",
      "[LOAD] 311_seg_028.png (y=1) superpix=566\n",
      "[LOAD] 315_seg_047.png (y=1) superpix=527\n",
      "[LOAD] 317_seg_007.png (y=1) superpix=614\n",
      "[LOAD] 319_seg_011.png (y=1) superpix=542\n",
      "[LOAD] 319_seg_013.png (y=1) superpix=612\n",
      "[LOAD] 321_seg_008.png (y=1) superpix=665\n",
      "[LOAD] 322_seg_007.png (y=1) superpix=543\n",
      "[LOAD] 325_seg_010.png (y=1) superpix=479\n",
      "[LOAD] 325_seg_011.png (y=1) superpix=450\n",
      "[LOAD] 325_seg_012.png (y=1) superpix=449\n",
      "[LOAD] 329_seg_005.png (y=1) superpix=595\n",
      "[LOAD] 329_seg_007.png (y=1) superpix=610\n",
      "[LOAD] 333_seg_023.png (y=1) superpix=562\n",
      "[OK] Modelo guardado en out_unsup_2sets/model_unsup.joblib\n",
      "[OK] Guardado: out_unsup_2sets/results_per_image.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Umbral y métricas: out_unsup_2sets/threshold_report.txt\n",
      "\n",
      "=== Mejor umbral en parasite_area_fraction_RBC ===\n",
      "{'thr': 0.0008108108108107561, 'f1': 0.6877828054298643, 'acc': 0.724, 'prec': 0.7916666666666666, 'rec': 0.608, 'auc': 0.7106239999999999}\n",
      "\n",
      "Aciertos por set:\n",
      "           mean     sum   count\n",
      "        correct correct correct\n",
      "set                            \n",
      "nosanos   0.608      76     125\n",
      "sanos     0.840     105     125\n",
      "Listo ✅  Figuras en ./out_unsup_2sets/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# NO SUPERVISADO con dos carpetas:\n",
    "#   ./sanos   (negativos)\n",
    "#   ./nosanos (positivos)\n",
    "#\n",
    "# ROI RBC + SLIC + features (LAB/LCH/grad/Gabor)\n",
    "# KMeans GLOBAL -> etiqueta \"parásito\" por score (C* + textura - dist hue magenta)\n",
    "# Selección de umbral (F1) sobre parasite_area_fraction_RBC\n",
    "# + GRÁFICAS: ROC, PR, F1-vs-umbral, histogramas, matriz de confusión\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from skimage import color as skcolor, img_as_ubyte\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from skimage.filters import gabor\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import (remove_small_objects, remove_small_holes,\n",
    "                                binary_opening, binary_closing, disk)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# ------------------ Carpetas ------------------\n",
    "DIR_NEG = \"./sampled/sanos\"    # sin parásito (y_true = 0)\n",
    "DIR_POS = \"./sampled/nosanos\"  # con parásito (y_true = 1)\n",
    "\n",
    "OUT_DIR = Path(\"./out_unsup_2sets\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = OUT_DIR / \"model_unsup.joblib\"\n",
    "PER_IMAGE_CSV = OUT_DIR / \"results_per_image.csv\"\n",
    "THRESH_REPORT = OUT_DIR / \"threshold_report.txt\"\n",
    "\n",
    "# ------------------ SLIC / Gabor / Clustering ------------------\n",
    "K_SUPERPIXELS = 600\n",
    "COMPACTNESS = 10.0\n",
    "SIGMA_SLIC = 1.0\n",
    "\n",
    "GABOR_FREQUENCIES = [0.1, 0.2, 0.3]\n",
    "GABOR_THETAS = [0, np.pi/6, np.pi/3, np.pi/2, 2*np.pi/3, 5*np.pi/6]\n",
    "\n",
    "K_CLUSTERS = 4  # clusters globales\n",
    "\n",
    "# ------------------ Morfología ------------------\n",
    "OPENING_RADIUS = 2\n",
    "CLOSING_RADIUS = 2\n",
    "HOLE_MIN_SIZE = 64\n",
    "COMP_MIN_SIZE = 64\n",
    "\n",
    "# ------------------ Scoring \"parásito\" dentro de RBC ------------------\n",
    "TARGET_H_DEG = 320.0     # magenta/púrpura\n",
    "H_BAND_DEG   = 50.0\n",
    "W_C = 1.0                # peso C* (croma)\n",
    "W_T = 0.7                # peso textura (gradL + gabor)\n",
    "W_H = 0.6                # penalización distancia de hue\n",
    "\n",
    "# ------------------ Utils ------------------\n",
    "def read_rgb_float01(path: str) -> np.ndarray:\n",
    "    arr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if arr is None:\n",
    "        raise FileNotFoundError(f\"No se puede leer: {path}\")\n",
    "    arr = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)\n",
    "    return (arr.astype(np.float32) / 255.0)\n",
    "\n",
    "def normalize_by_ref(rgb: np.ndarray, ref: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    norm = rgb / (ref + eps)\n",
    "    norm = np.nan_to_num(norm, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return np.clip(norm, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def gradients_L_from_lab(lab: np.ndarray) -> np.ndarray:\n",
    "    L = lab[..., 0]\n",
    "    Ln = (L - L.min()) / (L.max() - L.min() + 1e-8)\n",
    "    gx = cv2.Sobel(Ln.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(Ln.astype(np.float32), cv2.CV_32F, 0, 1, ksize=3)\n",
    "    return np.sqrt(gx*gx + gy*gy)\n",
    "\n",
    "def gabor_bank(gray01: np.ndarray, freqs, thetas):\n",
    "    feats = []\n",
    "    for f in freqs:\n",
    "        for t in thetas:\n",
    "            real, imag = gabor(gray01, frequency=f, theta=t)\n",
    "            feats.append(np.sqrt(real**2 + imag**2).astype(np.float32))\n",
    "    return feats\n",
    "\n",
    "def pixel_features(rgb01: np.ndarray):\n",
    "    lab = skcolor.rgb2lab(rgb01)\n",
    "    lch = skcolor.lab2lch(lab)\n",
    "    L = lab[...,0].astype(np.float32)\n",
    "    a = lab[...,1].astype(np.float32)\n",
    "    b = lab[...,2].astype(np.float32)\n",
    "    C = lch[...,1].astype(np.float32)\n",
    "    h = lch[...,2].astype(np.float32)\n",
    "    gradL = gradients_L_from_lab(lab).astype(np.float32)\n",
    "    Ln = (L - L.min()) / (L.max() - L.min() + 1e-8)\n",
    "    gabs = gabor_bank(Ln, GABOR_FREQUENCIES, GABOR_THETAS)\n",
    "    feat_list = [L, a, b, C, h, gradL] + gabs\n",
    "    feats = np.stack(feat_list, axis=-1)  # (H,W,F)\n",
    "    return feats, lab\n",
    "\n",
    "def rbc_mask_from_lab(rgb01: np.ndarray) -> np.ndarray:\n",
    "    lab = skcolor.rgb2lab(rgb01)\n",
    "    lch = skcolor.lab2lch(lab)\n",
    "    L = lab[...,0]; a = lab[...,1]; C = lch[...,1]\n",
    "    tL = max(20.0, np.percentile(L, 60))\n",
    "    tC = max(5.0,  np.percentile(C, 50))\n",
    "    ta = max(0.0,  np.percentile(a, 45))\n",
    "    mask = (L > tL) & (C > tC) & (a > ta)\n",
    "    mask = remove_small_objects(mask, min_size=400)\n",
    "    mask = binary_opening(mask, disk(3))\n",
    "    mask = binary_closing(mask, disk(5))\n",
    "    mask = remove_small_holes(mask, area_threshold=200)\n",
    "    labimg = label(mask)\n",
    "    if labimg.max() == 0:\n",
    "        return mask\n",
    "    areas = [(r.label, r.area) for r in regionprops(labimg)]\n",
    "    best = max(areas, key=lambda x: x[1])[0]\n",
    "    mask = (labimg == best)\n",
    "    mask = remove_small_holes(mask, area_threshold=2000)\n",
    "    return mask\n",
    "\n",
    "def assign_superpixels_to_roi(segments: np.ndarray, roi_mask: np.ndarray, thr=0.5):\n",
    "    spx_ids = np.unique(segments)\n",
    "    in_roi = []\n",
    "    for sid in spx_ids:\n",
    "        m = (segments == sid)\n",
    "        frac = np.count_nonzero(roi_mask & m) / float(np.count_nonzero(m))\n",
    "        in_roi.append(frac >= thr)\n",
    "    return spx_ids, np.array(in_roi, dtype=bool)\n",
    "\n",
    "def circular_hue_distance_deg(h, target):\n",
    "    d = np.abs((h - target + 180) % 360 - 180)\n",
    "    return d\n",
    "\n",
    "def choose_parasite_cluster_by_score(agg_means, agg_stds, labels, spx_ids, spx_in_roi, F_each):\n",
    "    mean_C = agg_means[:, 3]\n",
    "    mean_h = agg_means[:, 4]\n",
    "    mean_grad = agg_means[:, 5]\n",
    "    n_gab = F_each - 6\n",
    "    if n_gab > 0:\n",
    "        gabor_means = agg_means[:, 6:6+n_gab].mean(axis=1)\n",
    "        texture = 0.5*mean_grad + 0.5*gabor_means\n",
    "    else:\n",
    "        texture = mean_grad\n",
    "    hue_dist = circular_hue_distance_deg(mean_h, TARGET_H_DEG)\n",
    "    hue_penalty = np.clip(hue_dist / H_BAND_DEG, 0.0, 1.0)\n",
    "    def rnorm(x):\n",
    "        p1, p99 = np.percentile(x, 1), np.percentile(x, 99)\n",
    "        return np.clip((x - p1) / (p99 - p1 + 1e-8), 0, 1)\n",
    "    Cn = rnorm(mean_C)\n",
    "    Tn = rnorm(texture)\n",
    "    spx_score = W_C*Cn + W_T*Tn - W_H*hue_penalty\n",
    "    spx_score[~spx_in_roi] = -np.inf\n",
    "    k_scores = []\n",
    "    for k in np.unique(labels):\n",
    "        m = (labels == k) & spx_in_roi\n",
    "        if not np.any(m):\n",
    "            k_scores.append(-np.inf)\n",
    "        else:\n",
    "            k_scores.append(np.mean(spx_score[m]))\n",
    "    parasite_k = int(np.argmax(k_scores))\n",
    "    return parasite_k, k_scores\n",
    "\n",
    "def overlay_mask(rgb01, mask, alpha=0.45):\n",
    "    out = rgb01.copy()\n",
    "    color = np.array([1.0, 0.0, 1.0], dtype=np.float32)\n",
    "    out[mask] = (1 - alpha) * out[mask] + alpha * color\n",
    "    return out\n",
    "\n",
    "def put_tag(img_rgb01: np.ndarray, text: str, pos=(10, 30)):\n",
    "    img8 = img_as_ubyte(img_rgb01.copy())\n",
    "    cv2.putText(img8, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(img8, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    return img8\n",
    "\n",
    "def colorize_clusters(segments: np.ndarray, labels: np.ndarray):\n",
    "    H, W = segments.shape\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    out = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    for sid, lbl in zip(np.unique(segments), labels):\n",
    "        out[segments == sid] = cmap(lbl % 10)[:3]\n",
    "    return out\n",
    "\n",
    "def collect_images(root: str):\n",
    "    exts = [\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.tiff\", \"*.bmp\"]\n",
    "    files = []\n",
    "    for ext in exts:\n",
    "        files += list(Path(root).rglob(ext))\n",
    "    return sorted([p for p in files if not p.name.endswith(\"_ref.png\")])\n",
    "\n",
    "def load_prepare(img_path: Path):\n",
    "    ref_path = Path(str(img_path).rsplit(\".\", 1)[0] + \"_ref.png\")\n",
    "    rgb = read_rgb_float01(str(img_path))\n",
    "    if ref_path.exists():\n",
    "        ref = read_rgb_float01(str(ref_path))\n",
    "        rgbn = normalize_by_ref(rgb, ref)\n",
    "    else:\n",
    "        rgbn = rgb\n",
    "    feats_px, lab = pixel_features(rgbn)\n",
    "    H, W, F = feats_px.shape\n",
    "    segments = slic(rgbn, n_segments=K_SUPERPIXELS, compactness=COMPACTNESS,\n",
    "                    sigma=SIGMA_SLIC, start_label=0, channel_axis=-1)\n",
    "    spx_ids = np.unique(segments)\n",
    "    X = feats_px.reshape(-1, F)\n",
    "    s = segments.reshape(-1)\n",
    "    means = np.zeros((spx_ids.size, F), dtype=np.float32)\n",
    "    stds  = np.zeros_like(means)\n",
    "    sizes = np.zeros((spx_ids.size,), dtype=np.int32)\n",
    "    for i, sid in enumerate(spx_ids):\n",
    "        m = (s == sid)\n",
    "        Xi = X[m]\n",
    "        means[i] = Xi.mean(axis=0)\n",
    "        stds[i]  = Xi.std(axis=0)\n",
    "        sizes[i] = np.count_nonzero(m)\n",
    "    agg = np.concatenate([means, stds], axis=1)\n",
    "    rbc_mask = rbc_mask_from_lab(rgbn)\n",
    "    spx_ids, spx_in_roi = assign_superpixels_to_roi(segments, rbc_mask, thr=0.5)\n",
    "    return dict(rgb=rgbn, segments=segments, agg=agg, means=means, stds=stds,\n",
    "                spx_ids=spx_ids, sizes=sizes, F_each=F, rbc_mask=rbc_mask)\n",
    "\n",
    "# ------------------ Gráficas auxiliares ------------------\n",
    "def plot_roc_pr(y_true, scores, out_dir: Path):\n",
    "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
    "    auc = roc_auc_score(y_true, scores)\n",
    "    prec, rec, _ = precision_recall_curve(y_true, scores)\n",
    "    ap = average_precision_score(y_true, scores)\n",
    "\n",
    "    plt.figure(figsize=(5.5,5))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC={auc:.3f}\")\n",
    "    plt.plot([0,1], [0,1], \"--\", lw=1)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / \"roc_curve.png\", dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(5.5,5))\n",
    "    plt.plot(rec, prec, lw=2, label=f\"AP={ap:.3f}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision–Recall curve\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / \"precision_recall_curve.png\", dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "def plot_f1_vs_threshold(y_true, scores, grid, out_dir: Path):\n",
    "    f1s, accs = [], []\n",
    "    for thr in grid:\n",
    "        y_pred = (scores >= thr).astype(int)\n",
    "        f1s.append(f1_score(y_true, y_pred, zero_division=0))\n",
    "        accs.append(accuracy_score(y_true, y_pred))\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(grid, f1s, label=\"F1\", lw=2)\n",
    "    plt.plot(grid, accs, label=\"Accuracy\", lw=1.5)\n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.title(\"F1 / Accuracy vs threshold\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / \"f1_accuracy_vs_threshold.png\", dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "def plot_score_histograms(df, out_dir: Path, col=\"parasite_area_fraction_RBC\"):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for name, sub in df.groupby(\"set\"):\n",
    "        plt.hist(sub[col], bins=30, alpha=0.6, label=name)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(f\"Histogram of {col} by set\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"hist_{col}_by_set.png\", dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, out_path: Path, title=\"Confusion matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"sano(0)\",\"nosano(1)\"])\n",
    "    fig, ax = plt.subplots(figsize=(4.8,4.8))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=False)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "# ------------------ Pipeline principal ------------------\n",
    "def run_pipeline():\n",
    "    # 1) Cargar listas con etiqueta de verdad\n",
    "    imgs_neg = [(p, 0) for p in collect_images(DIR_NEG)]\n",
    "    imgs_pos = [(p, 1) for p in collect_images(DIR_POS)]\n",
    "    all_imgs = imgs_neg + imgs_pos\n",
    "    if not all_imgs:\n",
    "        raise RuntimeError(\"No se encontraron imágenes en ./sanos o ./nosanos\")\n",
    "\n",
    "    print(f\"Sanos (negativos): {len(imgs_neg)} | Nosanos (positivos): {len(imgs_pos)}\")\n",
    "\n",
    "    # 2) Cargar y acumular superpíxeles\n",
    "    per_image = []\n",
    "    all_agg = []\n",
    "    for p, y in all_imgs:\n",
    "        data = load_prepare(p)\n",
    "        per_image.append((p, y, data))\n",
    "        all_agg.append(data[\"agg\"])\n",
    "        print(f\"[LOAD] {p.name} (y={y}) superpix={data['agg'].shape[0]}\")\n",
    "\n",
    "    X_all = np.vstack(all_agg).astype(np.float32)\n",
    "\n",
    "    # 3) Escalado + KMeans global\n",
    "    scaler = StandardScaler().fit(X_all)\n",
    "    Xs_all = scaler.transform(X_all)\n",
    "    kmeans = KMeans(n_clusters=K_CLUSTERS, n_init=50, random_state=42).fit(Xs_all)\n",
    "    joblib.dump({\"scaler\": scaler, \"kmeans\": kmeans}, MODEL_PATH)\n",
    "    print(f\"[OK] Modelo guardado en {MODEL_PATH}\")\n",
    "\n",
    "    # 4) Pasada por imagen\n",
    "    rows = []\n",
    "    for p, y, data in per_image:\n",
    "        rgb = data[\"rgb\"]; seg = data[\"segments\"]\n",
    "        agg = data[\"agg\"]; means = data[\"means\"]; stds = data[\"stds\"]\n",
    "        spx_ids = data[\"spx_ids\"]; sizes = data[\"sizes\"]; F_each = data[\"F_each\"]\n",
    "        rbc_mask = data[\"rbc_mask\"]\n",
    "\n",
    "        X_img = scaler.transform(agg.astype(np.float32))\n",
    "        lbls = kmeans.predict(X_img)\n",
    "\n",
    "        _, spx_in_roi = assign_superpixels_to_roi(seg, rbc_mask, thr=0.5)\n",
    "        parasite_k, k_scores = choose_parasite_cluster_by_score(means, stds, lbls, spx_ids, spx_in_roi, F_each)\n",
    "\n",
    "        mask_par = np.isin(seg, spx_ids[lbls == parasite_k])\n",
    "        mask_par_roi = mask_par & rbc_mask\n",
    "\n",
    "        pix_par_global = int(np.count_nonzero(mask_par))\n",
    "        pix_tot_global = int(mask_par.size)\n",
    "        frac_global = pix_par_global / max(1, pix_tot_global)\n",
    "\n",
    "        pix_par_roi = int(np.count_nonzero(mask_par_roi))\n",
    "        pix_tot_roi = int(np.count_nonzero(rbc_mask))\n",
    "        frac_roi = pix_par_roi / max(1, pix_tot_roi)\n",
    "\n",
    "        # Guardar overlays por set\n",
    "        split_dir = OUT_DIR / (\"neg\" if y == 0 else \"pos\")\n",
    "        split_dir.mkdir(parents=True, exist_ok=True)\n",
    "        clusters_rgb = colorize_clusters(seg, lbls)\n",
    "        cv2.imwrite(str(split_dir / f\"{p.stem}_clusters_overlay.png\"),\n",
    "                    cv2.cvtColor(img_as_ubyte(mark_boundaries(clusters_rgb, seg)), cv2.COLOR_RGB2BGR))\n",
    "        overlay_par = overlay_mask(rgb, mask_par_roi, alpha=0.45)\n",
    "        tag = f\"Parasite(ROI) k={parasite_k}, score={k_scores[parasite_k]:.2f}, fracROI={frac_roi:.3f}\"\n",
    "        out_tag = put_tag(overlay_par, tag)\n",
    "        cv2.imwrite(str(split_dir / f\"{p.stem}_parasite_overlay.png\"),\n",
    "                    cv2.cvtColor(out_tag, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        rows.append({\n",
    "            \"image\": p.name,\n",
    "            \"set\": \"sanos\" if y == 0 else \"nosanos\",\n",
    "            \"y_true\": y,\n",
    "            \"parasite_cluster\": parasite_k,\n",
    "            \"score_parasite_cluster\": float(k_scores[parasite_k]),\n",
    "            \"pixels_parasite_global\": pix_par_global,\n",
    "            \"pixels_total_global\": pix_tot_global,\n",
    "            \"parasite_area_fraction_global\": frac_global,\n",
    "            \"pixels_parasite_RBC\": pix_par_roi,\n",
    "            \"pixels_RBC\": pix_tot_roi,\n",
    "            \"parasite_area_fraction_RBC\": frac_roi\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(PER_IMAGE_CSV, index=False)\n",
    "    print(f\"[OK] Guardado: {PER_IMAGE_CSV}\")\n",
    "\n",
    "    # 5) Selección de umbral sobre el score por imagen\n",
    "    #    Por defecto usamos la fracción en la ROI del glóbulo:\n",
    "    scores = df[\"parasite_area_fraction_RBC\"].to_numpy()\n",
    "    # >>> Si prefieres usar el score del clúster:\n",
    "    # scores = df[\"score_parasite_cluster\"].to_numpy()\n",
    "\n",
    "    y_true = df[\"y_true\"].to_numpy().astype(int)\n",
    "\n",
    "    if len(scores) == 0:\n",
    "        raise RuntimeError(\"No se generaron scores por imagen.\")\n",
    "\n",
    "    uniq = np.unique(scores)\n",
    "    if len(uniq) < 5:\n",
    "        grid = np.linspace(scores.min(), scores.max(), 101)\n",
    "    else:\n",
    "        grid = np.quantile(scores, np.linspace(0, 1, 201))\n",
    "\n",
    "    best = {\"thr\": None, \"f1\": -1, \"acc\": 0, \"prec\": 0, \"rec\": 0, \"auc\": None}\n",
    "    for thr in grid:\n",
    "        y_pred = (scores >= thr).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "        if f1 > best[\"f1\"]:\n",
    "            best.update(dict(thr=float(thr), f1=float(f1), acc=float(acc),\n",
    "                             prec=float(prec), rec=float(rec)))\n",
    "\n",
    "    # AUC (independiente del umbral)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, scores)\n",
    "        best[\"auc\"] = float(auc)\n",
    "    except Exception:\n",
    "        best[\"auc\"] = None\n",
    "\n",
    "    # 6) Aplicar mejor umbral y guardar predicciones\n",
    "    df[\"y_pred\"] = (scores >= best[\"thr\"]).astype(int)\n",
    "    df[\"correct\"] = (df[\"y_pred\"] == df[\"y_true\"]).astype(int)\n",
    "    df.to_csv(PER_IMAGE_CSV, index=False)\n",
    "\n",
    "    # 7) Guardar reporte de umbral\n",
    "    with open(THRESH_REPORT, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=== Threshold selection on parasite_area_fraction_RBC ===\\n\")\n",
    "        f.write(json.dumps(best, indent=2, ensure_ascii=False))\n",
    "        f.write(\"\\n\\nConfusion by set:\\n\")\n",
    "        for s in [\"sanos\", \"nosanos\"]:\n",
    "            sub = df[df[\"set\"] == s]\n",
    "            if len(sub) == 0:\n",
    "                continue\n",
    "            acc_s = accuracy_score(sub[\"y_true\"], sub[\"y_pred\"])\n",
    "            prec_s = precision_score(sub[\"y_true\"], sub[\"y_pred\"], zero_division=0)\n",
    "            rec_s = recall_score(sub[\"y_true\"], sub[\"y_pred\"])\n",
    "            f1_s = f1_score(sub[\"y_true\"], sub[\"y_pred\"], zero_division=0)\n",
    "            f.write(f\"- {s}: acc={acc_s:.3f}, prec={prec_s:.3f}, rec={rec_s:.3f}, f1={f1_s:.3f}\\n\")\n",
    "    print(f\"[OK] Umbral y métricas: {THRESH_REPORT}\")\n",
    "\n",
    "    # 8) GRÁFICAS\n",
    "    # ROC y PR\n",
    "    plot_roc_pr(y_true, scores, OUT_DIR)\n",
    "    # F1 vs umbral (y accuracy)\n",
    "    plot_f1_vs_threshold(y_true, scores, grid, OUT_DIR)\n",
    "    # Histograma de scores por set\n",
    "    plot_score_histograms(df, OUT_DIR, col=\"parasite_area_fraction_RBC\")\n",
    "\n",
    "    # Matriz de confusión global y por set\n",
    "    plot_confusion(y_true, df[\"y_pred\"].to_numpy(), OUT_DIR / \"confusion_matrix_overall.png\",\n",
    "                   title=\"Confusion matrix (overall)\")\n",
    "    for s in [\"sanos\", \"nosanos\"]:\n",
    "        sub = df[df[\"set\"] == s]\n",
    "        if len(sub):\n",
    "            plot_confusion(sub[\"y_true\"].to_numpy(), sub[\"y_pred\"].to_numpy(),\n",
    "                           OUT_DIR / f\"confusion_matrix_{s}.png\",\n",
    "                           title=f\"Confusion matrix ({s})\")\n",
    "\n",
    "    # 9) Resumen consola\n",
    "    print(\"\\n=== Mejor umbral en parasite_area_fraction_RBC ===\")\n",
    "    print(best)\n",
    "    print(\"\\nAciertos por set:\")\n",
    "    print(df.pivot_table(index=\"set\", values=\"correct\", aggfunc=[\"mean\",\"sum\",\"count\"]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()\n",
    "    print(\"Listo ✅  Figuras en ./out_unsup_2sets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Modelo cargado: out_unsup_2sets/model_unsup.joblib\n",
      "[THR] Intentando leer: /home/alejandro/Codes/Malaria/Segmentacion/out_unsup_2sets/threshold_report.txt\n",
      "[THR] Umbral cargado: 0.00081081\n",
      "[VAL] Sanos: 150 | Nosanos: 150\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VALIDACIÓN (usa modelo ya entrenado)\n",
    "#   ./val_sanos    (negativos)\n",
    "#   ./val_nosanos  (positivos)\n",
    "#\n",
    "# Carga scaler+kmeans + umbral (robusto), calcula scores por imagen,\n",
    "# selecciona/aplica umbral robusto y genera métricas + gráficas.\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import os, re, json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from skimage import color as skcolor, img_as_ubyte\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from skimage.filters import gabor\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import (remove_small_objects, remove_small_holes,\n",
    "                                binary_opening, binary_closing, disk)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# ----------- Rutas -----------\n",
    "DIR_VAL_NEG = \"./val/sanos\"\n",
    "DIR_VAL_POS = \"./val/nosanos\"\n",
    "\n",
    "TRAIN_OUT_DIR = Path(\"./out_unsup_2sets\")                     # donde quedó tu modelo y threshold\n",
    "MODEL_PATH = TRAIN_OUT_DIR / \"model_unsup.joblib\"             # << se carga aquí\n",
    "THRESH_REPORT = TRAIN_OUT_DIR / \"threshold_report.txt\"        # << umbral entrenado (opcional)\n",
    "\n",
    "VAL_OUT_DIR = Path(\"./out_unsup_val\")\n",
    "VAL_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PER_IMAGE_CSV = VAL_OUT_DIR / \"results_per_image.csv\"\n",
    "VAL_METRICS_JSON = VAL_OUT_DIR / \"val_metrics.json\"\n",
    "\n",
    "# ----------- Parámetros (mismos del entrenamiento) -----------\n",
    "K_SUPERPIXELS = 600\n",
    "COMPACTNESS = 10.0\n",
    "SIGMA_SLIC = 1.0\n",
    "\n",
    "GABOR_FREQUENCIES = [0.1, 0.2, 0.3]\n",
    "GABOR_THETAS = [0, np.pi/6, np.pi/3, np.pi/2, 2*np.pi/3, 5*np.pi/6]\n",
    "\n",
    "# Scoring del clúster \"parásito\"\n",
    "TARGET_H_DEG = 320.0\n",
    "H_BAND_DEG   = 50.0\n",
    "W_C = 1.0\n",
    "W_T = 0.7\n",
    "W_H = 0.6\n",
    "\n",
    "SAVE_OVERLAYS = True     # guarda PNGs de overlay por imagen\n",
    "MIN_RBC_PIX   = 2000     # sanidad: tamaño mínimo del RBC para confiar en la ROI\n",
    "\n",
    "# ------------------ Utils de imagen/feats ------------------\n",
    "def read_rgb_float01(path: str) -> np.ndarray:\n",
    "    arr = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if arr is None:\n",
    "        raise FileNotFoundError(f\"No se puede leer: {path}\")\n",
    "    arr = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)\n",
    "    return (arr.astype(np.float32) / 255.0)\n",
    "\n",
    "def normalize_by_ref(rgb: np.ndarray, ref: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n",
    "    norm = rgb / (ref + eps)\n",
    "    norm = np.nan_to_num(norm, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return np.clip(norm, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def gradients_L_from_lab(lab: np.ndarray) -> np.ndarray:\n",
    "    L = lab[..., 0]\n",
    "    Ln = (L - L.min()) / (L.max() - L.min() + 1e-8)\n",
    "    gx = cv2.Sobel(Ln.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(Ln.astype(np.float32), cv2.CV_32F, 0, 1, ksize=3)\n",
    "    return np.sqrt(gx*gx + gy*gy)\n",
    "\n",
    "def gabor_bank(gray01: np.ndarray, freqs, thetas):\n",
    "    feats = []\n",
    "    for f in freqs:\n",
    "        for t in thetas:\n",
    "            real, imag = gabor(gray01, frequency=f, theta=t)\n",
    "            feats.append(np.sqrt(real**2 + imag**2).astype(np.float32))\n",
    "    return feats\n",
    "\n",
    "def pixel_features(rgb01: np.ndarray):\n",
    "    lab = skcolor.rgb2lab(rgb01)\n",
    "    lch = skcolor.lab2lch(lab)\n",
    "    L = lab[...,0].astype(np.float32)\n",
    "    a = lab[...,1].astype(np.float32)\n",
    "    b = lab[...,2].astype(np.float32)\n",
    "    C = lch[...,1].astype(np.float32)\n",
    "    h = lch[...,2].astype(np.float32)\n",
    "    gradL = gradients_L_from_lab(lab).astype(np.float32)\n",
    "    Ln = (L - L.min()) / (L.max() - L.min() + 1e-8)\n",
    "    gabs = gabor_bank(Ln, GABOR_FREQUENCIES, GABOR_THETAS)\n",
    "    feat_list = [L, a, b, C, h, gradL] + gabs\n",
    "    feats = np.stack(feat_list, axis=-1)  # (H,W,F)\n",
    "    return feats, lab\n",
    "\n",
    "def rbc_mask_from_lab(rgb01: np.ndarray) -> np.ndarray:\n",
    "    lab = skcolor.rgb2lab(rgb01)\n",
    "    lch = skcolor.lab2lch(lab)\n",
    "    L = lab[...,0]; a = lab[...,1]; C = lch[...,1]\n",
    "    tL = max(20.0, np.percentile(L, 60))\n",
    "    tC = max(5.0,  np.percentile(C, 50))\n",
    "    ta = max(0.0,  np.percentile(a, 45))\n",
    "    mask = (L > tL) & (C > tC) & (a > ta)\n",
    "    mask = remove_small_objects(mask, min_size=400)\n",
    "    mask = binary_opening(mask, disk(3))\n",
    "    mask = binary_closing(mask, disk(5))\n",
    "    mask = remove_small_holes(mask, area_threshold=200)\n",
    "    labimg = label(mask)\n",
    "    if labimg.max() == 0:\n",
    "        return mask\n",
    "    areas = [(r.label, r.area) for r in regionprops(labimg)]\n",
    "    best = max(areas, key=lambda x: x[1])[0]\n",
    "    mask = (labimg == best)\n",
    "    mask = remove_small_holes(mask, area_threshold=2000)\n",
    "    return mask\n",
    "\n",
    "def assign_superpixels_to_roi(segments: np.ndarray, roi_mask: np.ndarray, thr=0.5):\n",
    "    spx_ids = np.unique(segments)\n",
    "    in_roi = []\n",
    "    for sid in spx_ids:\n",
    "        m = (segments == sid)\n",
    "        frac = np.count_nonzero(roi_mask & m) / float(np.count_nonzero(m))\n",
    "        in_roi.append(frac >= thr)\n",
    "    return spx_ids, np.array(in_roi, dtype=bool)\n",
    "\n",
    "def circular_hue_distance_deg(h, target):\n",
    "    d = np.abs((h - target + 180) % 360 - 180)\n",
    "    return d\n",
    "\n",
    "def choose_parasite_cluster_by_score(agg_means, agg_stds, labels, spx_ids, spx_in_roi, F_each):\n",
    "    # agg_means: columnas [L, a, b, C, h, gradL, gabor...]\n",
    "    mean_C = agg_means[:, 3]\n",
    "    mean_h = agg_means[:, 4]\n",
    "    mean_grad = agg_means[:, 5]\n",
    "    n_gab = F_each - 6\n",
    "    if n_gab > 0:\n",
    "        gabor_means = agg_means[:, 6:6+n_gab].mean(axis=1)\n",
    "        texture = 0.5*mean_grad + 0.5*gabor_means\n",
    "    else:\n",
    "        texture = mean_grad\n",
    "    hue_dist = circular_hue_distance_deg(mean_h, TARGET_H_DEG)\n",
    "    hue_penalty = np.clip(hue_dist / H_BAND_DEG, 0.0, 1.0)\n",
    "\n",
    "    def rnorm(x):\n",
    "        p1, p99 = np.percentile(x, 1), np.percentile(x, 99)\n",
    "        return np.clip((x - p1) / (p99 - p1 + 1e-8), 0, 1)\n",
    "\n",
    "    Cn = rnorm(mean_C)\n",
    "    Tn = rnorm(texture)\n",
    "    spx_score = W_C*Cn + W_T*Tn - W_H*hue_penalty\n",
    "    spx_score[~spx_in_roi] = -np.inf\n",
    "\n",
    "    k_scores = []\n",
    "    for k in np.unique(labels):\n",
    "        m = (labels == k) & spx_in_roi\n",
    "        if not np.any(m):\n",
    "            k_scores.append(-np.inf)\n",
    "        else:\n",
    "            k_scores.append(np.mean(spx_score[m]))\n",
    "    parasite_k = int(np.argmax(k_scores))\n",
    "    return parasite_k, k_scores\n",
    "\n",
    "def overlay_mask(rgb01, mask, alpha=0.45):\n",
    "    out = rgb01.copy()\n",
    "    color = np.array([1.0, 0.0, 1.0], dtype=np.float32)\n",
    "    out[mask] = (1 - alpha) * out[mask] + alpha * color\n",
    "    return out\n",
    "\n",
    "def put_tag(img_rgb01: np.ndarray, text: str, pos=(10, 30)):\n",
    "    img8 = img_as_ubyte(img_rgb01.copy())\n",
    "    cv2.putText(img8, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 3, cv2.LINE_AA)\n",
    "    cv2.putText(img8, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
    "    return img8\n",
    "\n",
    "def colorize_clusters(segments: np.ndarray, labels: np.ndarray):\n",
    "    H, W = segments.shape\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    out = np.zeros((H, W, 3), dtype=np.float32)\n",
    "    for sid, lbl in zip(np.unique(segments), labels):\n",
    "        out[segments == sid] = cmap(lbl % 10)[:3]\n",
    "    return out\n",
    "\n",
    "def collect_images(root: str):\n",
    "    exts = [\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.tif\", \"*.tiff\", \"*.bmp\"]\n",
    "    files = []\n",
    "    for ext in exts:\n",
    "        files += list(Path(root).rglob(ext))\n",
    "    return sorted([p for p in files if not p.name.endswith(\"_ref.png\")])\n",
    "\n",
    "def load_prepare(img_path: Path):\n",
    "    ref_path = Path(str(img_path).rsplit(\".\", 1)[0] + \"_ref.png\")\n",
    "    rgb = read_rgb_float01(str(img_path))\n",
    "    if ref_path.exists():\n",
    "        ref = read_rgb_float01(str(ref_path))\n",
    "        rgbn = normalize_by_ref(rgb, ref)\n",
    "    else:\n",
    "        rgbn = rgb\n",
    "    feats_px, lab = pixel_features(rgbn)\n",
    "    H, W, F = feats_px.shape\n",
    "    segments = slic(rgbn, n_segments=K_SUPERPIXELS, compactness=COMPACTNESS,\n",
    "                    sigma=SIGMA_SLIC, start_label=0, channel_axis=-1)\n",
    "    spx_ids = np.unique(segments)\n",
    "    X = feats_px.reshape(-1, F)\n",
    "    s = segments.reshape(-1)\n",
    "    means = np.zeros((spx_ids.size, F), dtype=np.float32)\n",
    "    stds  = np.zeros_like(means)\n",
    "    for i, sid in enumerate(spx_ids):\n",
    "        m = (s == sid)\n",
    "        Xi = X[m]\n",
    "        means[i] = Xi.mean(axis=0)\n",
    "        stds[i]  = Xi.std(axis=0)\n",
    "    agg = np.concatenate([means, stds], axis=1)\n",
    "    rbc_mask = rbc_mask_from_lab(rgbn)\n",
    "    spx_ids, spx_in_roi = assign_superpixels_to_roi(segments, rbc_mask, thr=0.5)\n",
    "    return dict(rgb=rgbn, segments=segments, agg=agg, means=means, stds=stds,\n",
    "                spx_ids=spx_ids, F_each=F, rbc_mask=rbc_mask)\n",
    "\n",
    "# ------------------ Umbral ROBUSTO y sanidad ------------------\n",
    "def load_threshold_report_robust(path: Path):\n",
    "    \"\"\"Devuelve float(thr) o None. Imprime diagnóstico de ruta y contenido.\"\"\"\n",
    "    abs_path = path.resolve()\n",
    "    print(f\"[THR] Intentando leer: {abs_path}\")\n",
    "    if not path.exists():\n",
    "        try:\n",
    "            listing = \"\\n - \".join([p.name for p in path.parent.iterdir()])\n",
    "        except Exception:\n",
    "            listing = \"(no se pudo listar la carpeta)\"\n",
    "        print(f\"[THR] No existe el archivo. Contenido de la carpeta:{os.linesep} - {listing}\")\n",
    "        return None\n",
    "\n",
    "    txt = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    i, j = txt.find(\"{\"), txt.rfind(\"}\")\n",
    "    thr = None\n",
    "    if i != -1 and j != -1 and j > i:\n",
    "        blob = txt[i:j+1]\n",
    "        try:\n",
    "            js = json.loads(blob)\n",
    "            thr = js.get(\"thr\", None)\n",
    "        except Exception as e:\n",
    "            print(f\"[THR] JSON principal no parseó: {e}\")\n",
    "    if thr is None:\n",
    "        m = re.search(r'\"thr\"\\s*:\\s*([-+eE0-9\\.]+)', txt)\n",
    "        if m:\n",
    "            try:\n",
    "                thr = float(m.group(1))\n",
    "            except:\n",
    "                thr = None\n",
    "\n",
    "    if thr is None:\n",
    "        print(\"[THR] No se pudo extraer 'thr' del archivo.\")\n",
    "    else:\n",
    "        print(f\"[THR] Umbral cargado: {float(thr):.8f}\")\n",
    "    return None if thr is None else float(thr)\n",
    "\n",
    "def safe_frac_roi(pix_par_roi, pix_tot_roi, min_rbc=MIN_RBC_PIX):\n",
    "    \"\"\"(frac_roi, roi_bad_flag). Si ROI es muy pequeña, frac=0 y bad=True.\"\"\"\n",
    "    if pix_tot_roi < min_rbc:\n",
    "        return 0.0, True\n",
    "    return pix_par_roi / float(max(1, pix_tot_roi)), False\n",
    "\n",
    "def midpoints_threshold_grid(scores: np.ndarray):\n",
    "    \"\"\"Umbrales en puntos medios entre scores únicos (evita usar el mínimo).\"\"\"\n",
    "    u = np.unique(scores[~np.isnan(scores)])\n",
    "    if len(u) <= 1:\n",
    "        return np.array([u[0] + 1e-9]) if len(u) == 1 else np.array([0.5])\n",
    "    mids = (u[1:] + u[:-1]) / 2.0\n",
    "    return np.concatenate([np.array([u[0] + 1e-8]), mids])\n",
    "\n",
    "def best_threshold_by_f1(scores: np.ndarray, y_true: np.ndarray):\n",
    "    grid = midpoints_threshold_grid(scores)\n",
    "    best = {\"thr\": None, \"f1\": -1, \"acc\": 0, \"prec\": 0, \"rec\": 0}\n",
    "    for thr in grid:\n",
    "        y_pred = (scores > thr).astype(int)  # '>' evita degenerar con el mínimo\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred)\n",
    "        if f1 > best[\"f1\"]:\n",
    "            best.update(dict(thr=float(thr), f1=float(f1), acc=float(acc),\n",
    "                             prec=float(prec), rec=float(rec)))\n",
    "    return best, grid\n",
    "\n",
    "def apply_threshold(scores: np.ndarray, thr: float):\n",
    "    \"\"\"Aplica con '>' y advierte si todo queda 1 o 0.\"\"\"\n",
    "    y_pred = (scores > thr).astype(int)\n",
    "    if (y_pred == 1).all() or (y_pred == 0).all():\n",
    "        print(\"[WARN] Predicciones degeneradas: todo 1 o todo 0. Ajusta el threshold o revisa scores.\")\n",
    "    return y_pred\n",
    "\n",
    "def choose_threshold_robust(thr_loaded, scores, y_true, df=None, fallback_quantile=0.95):\n",
    "    \"\"\"\n",
    "    Valida/ajusta el umbral:\n",
    "      - si thr_loaded es None, NaN, <= min(scores) o >= max(scores) -> reoptimiza por F1\n",
    "      - si aún degenera -> usa cuantíl de 'sanos' (control de FPR)\n",
    "    \"\"\"\n",
    "    smin, smax = float(np.min(scores)), float(np.max(scores))\n",
    "    def degenerate(thr):\n",
    "        return (thr is None) or (not np.isfinite(thr)) or (thr <= smin) or (thr >= smax)\n",
    "\n",
    "    if degenerate(thr_loaded):\n",
    "        print(f\"[THR] Umbral cargado inválido o extremo: {thr_loaded}. Re-optimizo por F1…\")\n",
    "        best, grid = best_threshold_by_f1(scores, y_true)\n",
    "        thr_used = best[\"thr\"]\n",
    "        print(f\"[THR] Mejor F1 -> thr={thr_used:.6f} (F1={best['f1']:.3f})\")\n",
    "    else:\n",
    "        thr_used = float(thr_loaded)\n",
    "        grid = None\n",
    "        print(f\"[THR] Usando umbral cargado: {thr_used:.6f}\")\n",
    "\n",
    "    y_pred_try = (scores > thr_used).astype(int)\n",
    "    if (y_pred_try == 1).all() or (y_pred_try == 0).all():\n",
    "        print(\"[THR] Aún degenerado con ese umbral. Calibro por sanos (cuantil).\")\n",
    "        if df is not None and (y_true == 0).any():\n",
    "            thr_used = float(np.quantile(scores[y_true == 0], fallback_quantile))\n",
    "            print(f\"[THR] Nuevo thr (q={fallback_quantile:.2f} en sanos) = {thr_used:.6f}\")\n",
    "        else:\n",
    "            thr_used = float(np.quantile(scores, 0.5))\n",
    "            print(f\"[THR] Sin sanos disponibles; uso mediana global = {thr_used:.6f}\")\n",
    "        grid = None\n",
    "    return thr_used, grid\n",
    "\n",
    "# ------------------ Gráficas ------------------\n",
    "def plot_roc_pr(y_true, scores, out_dir: Path):\n",
    "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
    "    auc = roc_auc_score(y_true, scores)\n",
    "    prec, rec, _ = precision_recall_curve(y_true, scores)\n",
    "    ap = average_precision_score(y_true, scores)\n",
    "\n",
    "    plt.figure(figsize=(5.2,5))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC={auc:.3f}\")\n",
    "    plt.plot([0,1], [0,1], \"--\", lw=1)\n",
    "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC curve (validation)\"); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(out_dir / \"val_roc_curve.png\", dpi=160); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(5.2,5))\n",
    "    plt.plot(rec, prec, lw=2, label=f\"AP={ap:.3f}\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision–Recall (validation)\"); plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(out_dir / \"val_precision_recall_curve.png\", dpi=160); plt.close()\n",
    "\n",
    "def plot_f1_vs_threshold(y_true, scores, grid, out_dir: Path):\n",
    "    f1s, accs = [], []\n",
    "    for thr in grid:\n",
    "        y_pred = (scores > thr).astype(int)\n",
    "        f1s.append(f1_score(y_true, y_pred, zero_division=0))\n",
    "        accs.append(accuracy_score(y_true, y_pred))\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(grid, f1s, label=\"F1\", lw=2)\n",
    "    plt.plot(grid, accs, label=\"Accuracy\", lw=1.5)\n",
    "    plt.xlabel(\"threshold\"); plt.ylabel(\"score\"); plt.title(\"F1 / Acc vs threshold (validation)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.savefig(out_dir / \"val_f1_accuracy_vs_threshold.png\", dpi=160); plt.close()\n",
    "\n",
    "def plot_hist_with_thr(df, out_path, col=\"parasite_area_fraction_RBC\", thr=None):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for name, sub in df.groupby(\"set\"):\n",
    "        plt.hist(sub[col], bins=30, alpha=0.6, label=name)\n",
    "    if thr is not None:\n",
    "        plt.axvline(thr, color=\"k\", linestyle=\"--\", linewidth=1.5, label=f\"thr={thr:.4f}\")\n",
    "    plt.xlabel(col); plt.ylabel(\"count\"); plt.title(f\"Validation histogram of {col} by set\")\n",
    "    plt.legend(); plt.tight_layout(); plt.savefig(out_path, dpi=160); plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, out_path: Path, title=\"Confusion matrix (validation)\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"sano(0)\",\"nosano(1)\"])\n",
    "    fig, ax = plt.subplots(figsize=(4.8,4.8))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=False)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=160); plt.close()\n",
    "\n",
    "# ------------------ VALIDACIÓN (usa modelo entrenado) ------------------\n",
    "def evaluate_validation():\n",
    "    # A) Carga modelo entrenado\n",
    "    if not MODEL_PATH.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró el modelo entrenado: {MODEL_PATH}\")\n",
    "    bundle = joblib.load(MODEL_PATH)\n",
    "    scaler = bundle[\"scaler\"]; kmeans = bundle[\"kmeans\"]\n",
    "    print(\"[OK] Modelo cargado:\", MODEL_PATH)\n",
    "\n",
    "    # B) Carga umbral entrenado (robusto)\n",
    "    thr_loaded = load_threshold_report_robust(THRESH_REPORT)\n",
    "\n",
    "    # C) Carga imágenes de validación\n",
    "    imgs_neg = [(p, 0) for p in collect_images(DIR_VAL_NEG)]\n",
    "    imgs_pos = [(p, 1) for p in collect_images(DIR_VAL_POS)]\n",
    "    all_imgs = imgs_neg + imgs_pos\n",
    "    if not all_imgs:\n",
    "        raise RuntimeError(\"No se encontraron imágenes en ./val_sanos o ./val_nosanos\")\n",
    "    print(f\"[VAL] Sanos: {len(imgs_neg)} | Nosanos: {len(imgs_pos)}\")\n",
    "\n",
    "    # D) Pasada por imagen con modelo cargado\n",
    "    rows = []\n",
    "    for p, y in all_imgs:\n",
    "        data = load_prepare(p)\n",
    "        rgb = data[\"rgb\"]; seg = data[\"segments\"]\n",
    "        agg = data[\"agg\"]; means = data[\"means\"]; stds = data[\"stds\"]\n",
    "        spx_ids = data[\"spx_ids\"]; F_each = data[\"F_each\"]\n",
    "        rbc_mask = data[\"rbc_mask\"]\n",
    "\n",
    "        X_img = scaler.transform(agg.astype(np.float32))\n",
    "        lbls = kmeans.predict(X_img)\n",
    "\n",
    "        _, spx_in_roi = assign_superpixels_to_roi(seg, rbc_mask, thr=0.5)\n",
    "        parasite_k, k_scores = choose_parasite_cluster_by_score(means, stds, lbls, spx_ids, spx_in_roi, F_each)\n",
    "\n",
    "        # máscaras\n",
    "        mask_par = np.isin(seg, spx_ids[lbls == parasite_k])\n",
    "        mask_par_roi = mask_par & rbc_mask\n",
    "\n",
    "        # conteos y fracciones (con sanidad de ROI)\n",
    "        pix_par_global = int(np.count_nonzero(mask_par))\n",
    "        pix_tot_global = int(mask_par.size)\n",
    "        frac_global = pix_par_global / float(max(1, pix_tot_global))\n",
    "\n",
    "        pix_par_roi = int(np.count_nonzero(mask_par_roi))\n",
    "        pix_tot_roi = int(np.count_nonzero(rbc_mask))\n",
    "        frac_roi, roi_bad = safe_frac_roi(pix_par_roi, pix_tot_roi, min_rbc=MIN_RBC_PIX)\n",
    "\n",
    "        # overlays (opcionales)\n",
    "        if SAVE_OVERLAYS:\n",
    "            split_dir = VAL_OUT_DIR / (\"neg\" if y == 0 else \"pos\")\n",
    "            split_dir.mkdir(parents=True, exist_ok=True)\n",
    "            clusters_rgb = colorize_clusters(seg, lbls)\n",
    "            cv2.imwrite(str(split_dir / f\"{p.stem}_clusters_overlay.png\"),\n",
    "                        cv2.cvtColor(img_as_ubyte(mark_boundaries(clusters_rgb, seg)), cv2.COLOR_RGB2BGR))\n",
    "            overlay_par = overlay_mask(rgb, mask_par_roi, alpha=0.45)\n",
    "            tag = f\"VAL Parasite(ROI) k={parasite_k}, score={k_scores[parasite_k]:.2f}, fracROI={frac_roi:.3f}\"\n",
    "            out_tag = put_tag(overlay_par, tag)\n",
    "            cv2.imwrite(str(split_dir / f\"{p.stem}_parasite_overlay.png\"),\n",
    "                        cv2.cvtColor(out_tag, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        rows.append({\n",
    "            \"image\": p.name,\n",
    "            \"set\": \"sanos\" if y == 0 else \"nosanos\",\n",
    "            \"y_true\": y,\n",
    "            \"parasite_cluster\": parasite_k,\n",
    "            \"score_parasite_cluster\": float(k_scores[parasite_k]),\n",
    "            \"parasite_area_fraction_global\": frac_global,\n",
    "            \"parasite_area_fraction_RBC\": frac_roi,\n",
    "            \"rbc_invalid\": int(roi_bad)\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(PER_IMAGE_CSV, index=False)\n",
    "    print(f\"[VAL] Guardado: {PER_IMAGE_CSV}\")\n",
    "\n",
    "    # E) Scores y etiquetas\n",
    "    scores = df[\"parasite_area_fraction_RBC\"].to_numpy()\n",
    "    # >>> Para usar el score del clúster:\n",
    "    # scores = df[\"score_parasite_cluster\"].to_numpy()\n",
    "    y_true = df[\"y_true\"].to_numpy().astype(int)\n",
    "\n",
    "    print(f\"[VAL] scores: min={np.min(scores):.6f}, p50={np.median(scores):.6f}, max={np.max(scores):.6f}\")\n",
    "\n",
    "    # F) Eligir/validar umbral de manera robusta\n",
    "    thr_used, grid = choose_threshold_robust(thr_loaded, scores, y_true, df=df, fallback_quantile=0.95)\n",
    "\n",
    "    # G) Métricas (ROC/PR) y gráficas\n",
    "    plot_roc_pr(y_true, scores, VAL_OUT_DIR)\n",
    "    if grid is not None:\n",
    "        plot_f1_vs_threshold(y_true, scores, grid, VAL_OUT_DIR)\n",
    "\n",
    "    # histograma con línea de umbral\n",
    "    plot_hist_with_thr(df, VAL_OUT_DIR / \"val_hist_with_thr.png\",\n",
    "                       col=\"parasite_area_fraction_RBC\", thr=thr_used)\n",
    "\n",
    "    # H) Predicciones con el umbral usado (aplica con '>')\n",
    "    y_pred = apply_threshold(scores, thr_used)\n",
    "    df[\"y_pred\"] = y_pred\n",
    "    df[\"correct\"] = (y_pred == y_true).astype(int)\n",
    "    df.to_csv(PER_IMAGE_CSV, index=False)\n",
    "\n",
    "    # I) Métricas globales\n",
    "    metrics = {\n",
    "        \"threshold_used\": float(thr_used),\n",
    "        \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred)),\n",
    "    }\n",
    "    try:\n",
    "        metrics[\"auc\"] = float(roc_auc_score(y_true, scores))\n",
    "    except Exception:\n",
    "        metrics[\"auc\"] = None\n",
    "\n",
    "    # J) Matrices de confusión\n",
    "    plot_confusion(y_true, y_pred, VAL_OUT_DIR / \"val_confusion_matrix_overall.png\")\n",
    "    for s in [\"sanos\", \"nosanos\"]:\n",
    "        sub = df[df[\"set\"] == s]\n",
    "        if len(sub):\n",
    "            plot_confusion(sub[\"y_true\"].to_numpy(), sub[\"y_pred\"].to_numpy(),\n",
    "                           VAL_OUT_DIR / f\"val_confusion_matrix_{s}.png\",\n",
    "                           title=f\"Confusion matrix (validation, {s})\")\n",
    "\n",
    "    # K) Guardar métricas globales a JSON\n",
    "    with open(VAL_METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Resumen\n",
    "    print(\"\\n[VAL] Métricas globales:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"- {k}: {v:.4f}\" if isinstance(v, float) else f\"- {k}: {v}\")\n",
    "    print(\"\\n[VAL] Aciertos por set:\")\n",
    "    print(df.pivot_table(index=\"set\", values=\"correct\", aggfunc=[\"mean\",\"sum\",\"count\"]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_validation()\n",
    "    print(\"Listo ✅  Resultados en ./out_unsup_val/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31af73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
