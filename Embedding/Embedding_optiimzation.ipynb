{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2dde88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Device: cpu\n",
      "[CACHE] X_train sanos -> (250, 512)\n",
      "[CACHE] X_val sanos -> (250, 512) | X_val infectados -> (250, 512)\n",
      "[SHAPE] X_train=(250, 512) | X_val_sanos=(250, 512) | X_val_infectados=(250, 512)\n",
      "[GRID] PCA= 64 nu=0.01 gamma=scale   | AUC=0.807\n",
      "[GRID] PCA= 64 nu=0.01 gamma=0.001   | AUC=0.789\n",
      "[GRID] PCA= 64 nu=0.01 gamma=0.0001  | AUC=0.788\n",
      "[GRID] PCA= 64 nu=0.01 gamma=1e-05   | AUC=0.786\n",
      "[GRID] PCA= 64 nu=0.02 gamma=scale   | AUC=0.807\n",
      "[GRID] PCA= 64 nu=0.02 gamma=0.001   | AUC=0.789\n",
      "[GRID] PCA= 64 nu=0.02 gamma=0.0001  | AUC=0.788\n",
      "[GRID] PCA= 64 nu=0.02 gamma=1e-05   | AUC=0.787\n",
      "[GRID] PCA= 64 nu=0.05 gamma=scale   | AUC=0.807\n",
      "[GRID] PCA= 64 nu=0.05 gamma=0.001   | AUC=0.790\n",
      "[GRID] PCA= 64 nu=0.05 gamma=0.0001  | AUC=0.790\n",
      "[GRID] PCA= 64 nu=0.05 gamma=1e-05   | AUC=0.791\n",
      "[GRID] PCA= 64 nu=0.1  gamma=scale   | AUC=0.807\n",
      "[GRID] PCA= 64 nu=0.1  gamma=0.001   | AUC=0.789\n",
      "[GRID] PCA= 64 nu=0.1  gamma=0.0001  | AUC=0.789\n",
      "[GRID] PCA= 64 nu=0.1  gamma=1e-05   | AUC=0.789\n",
      "[GRID] PCA=128 nu=0.01 gamma=scale   | AUC=0.851\n",
      "[GRID] PCA=128 nu=0.01 gamma=0.001   | AUC=0.842\n",
      "[GRID] PCA=128 nu=0.01 gamma=0.0001  | AUC=0.842\n",
      "[GRID] PCA=128 nu=0.01 gamma=1e-05   | AUC=0.844\n",
      "[GRID] PCA=128 nu=0.02 gamma=scale   | AUC=0.851\n",
      "[GRID] PCA=128 nu=0.02 gamma=0.001   | AUC=0.842\n",
      "[GRID] PCA=128 nu=0.02 gamma=0.0001  | AUC=0.842\n",
      "[GRID] PCA=128 nu=0.02 gamma=1e-05   | AUC=0.843\n",
      "[GRID] PCA=128 nu=0.05 gamma=scale   | AUC=0.852\n",
      "[GRID] PCA=128 nu=0.05 gamma=0.001   | AUC=0.843\n",
      "[GRID] PCA=128 nu=0.05 gamma=0.0001  | AUC=0.842\n",
      "[GRID] PCA=128 nu=0.05 gamma=1e-05   | AUC=0.842\n",
      "[GRID] PCA=128 nu=0.1  gamma=scale   | AUC=0.852\n",
      "[GRID] PCA=128 nu=0.1  gamma=0.001   | AUC=0.843\n",
      "[GRID] PCA=128 nu=0.1  gamma=0.0001  | AUC=0.842\n",
      "[GRID] PCA=128 nu=0.1  gamma=1e-05   | AUC=0.842\n",
      "[BEST] AUC=0.852 con params={'pca': 128, 'nu': 0.1, 'gamma': 'scale'}\n",
      "[THR] FPR target 5% -> 1.486401\n",
      "[THR] Mejor F1 en validación -> 1.478797 (F1=0.853)\n",
      "\n",
      "[MÉTRICAS VALIDACIÓN]\n",
      "- threshold_used: 1.4788\n",
      "- f1: 0.8532\n",
      "- accuracy: 0.8720\n",
      "- precision: 1.0000\n",
      "- recall: 0.7440\n",
      "- auc: 0.8519\n",
      "- average_precision: 0.9002\n",
      "[OK] Guardado: out_oneclass_pca/pipeline_ocsvm_pca.joblib\n",
      "Artefactos en out_oneclass_pca\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PIPELINE: L2 → StandardScaler → PCA(whiten) → One-Class SVM\n",
    "# - Embeddings: ResNet18 (ImageNet) 512-D por imagen\n",
    "# - Train: solo 'sanos' (One-Class)\n",
    "# - Validación: 'sanos' vs 'no_sanos'\n",
    "# - Selección de hiperparámetros por AUC en validación (anomaly score)\n",
    "# - Umbral: mejor F1 (opción alternativa: FPR objetivo en sanos)\n",
    "# - Salidas: ./out_oneclass_pca/*\n",
    "# Requisitos: torch, torchvision, pillow, numpy, scikit-learn, matplotlib, joblib\n",
    "# ============================================================\n",
    "\n",
    "import os, json, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_recall_curve, average_precision_score,\n",
    "    roc_curve, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    f1_score, accuracy_score, precision_score, recall_score\n",
    ")\n",
    "import joblib\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ------------------- Rutas -------------------\n",
    "DIR_TRAIN_SANOS = Path(\"./sampled/sanos\")\n",
    "DIR_VAL_SANOS   = Path(\"./val/sanos\")     # si tienes otra carpeta para val-sanos, cámbiala aquí\n",
    "DIR_VAL_INFECT  = Path(\"./sampled/nosanos\")\n",
    "\n",
    "OUT_DIR = Path(\"./out_oneclass_pca\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CACHE_TRAIN_EMB = OUT_DIR / \"emb_train_sanos.npy\"\n",
    "CACHE_VALS_EMB  = OUT_DIR / \"emb_val_sanos.npy\"\n",
    "CACHE_VALI_EMB  = OUT_DIR / \"emb_val_nosanos.npy\"\n",
    "MODEL_PATH      = OUT_DIR / \"pipeline_ocsvm_pca.joblib\"\n",
    "VAL_CSV         = OUT_DIR / \"val_results.csv\"\n",
    "METRICS_JSON    = OUT_DIR / \"metrics.json\"\n",
    "\n",
    "# ------------------- Config -------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = 224\n",
    "BATCH = 32\n",
    "\n",
    "# Grid de hiperparámetros\n",
    "GRID_PCA = [64, 128]\n",
    "GRID_NU  = [0.01, 0.02, 0.05, 0.1]\n",
    "GRID_GAM = [\"scale\", 1e-3, 1e-4, 1e-5]\n",
    "\n",
    "# Umbral por FPR objetivo (conservador) en sanos\n",
    "FPR_TARGET = 0.05\n",
    "\n",
    "# ------------------- Utilidades -------------------\n",
    "def list_images(root: Path):\n",
    "    exts = {\".png\",\".jpg\",\".jpeg\",\".tif\",\".tiff\",\".bmp\"}\n",
    "    return sorted([p for p in root.rglob(\"*\") if p.suffix.lower() in exts])\n",
    "\n",
    "def ensure_non_empty(paths, msg):\n",
    "    if len(paths) == 0:\n",
    "        raise RuntimeError(msg)\n",
    "\n",
    "def build_model_resnet18():\n",
    "    # Compat con distintas versiones de torchvision\n",
    "    weights = None\n",
    "    try:\n",
    "        weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "        base = models.resnet18(weights=weights)\n",
    "    except Exception:\n",
    "        base = models.resnet18(pretrained=True)\n",
    "    emb_net = nn.Sequential(*list(base.children())[:-1]).to(DEVICE).eval()\n",
    "    # Transform preferido por weights; fallback a ImageNet mean/std\n",
    "    tfm = None\n",
    "    if weights is not None:\n",
    "        try:\n",
    "            base_tfm = weights.transforms()\n",
    "            tfm = transforms.Compose([\n",
    "                transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "                base_tfm\n",
    "            ])\n",
    "        except Exception:\n",
    "            pass\n",
    "    if tfm is None:\n",
    "        tfm = transforms.Compose([\n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    return emb_net, tfm\n",
    "\n",
    "@torch.no_grad()\n",
    "def embeddings_from_paths(paths, emb_net, tfm, batch=BATCH):\n",
    "    vecs = []\n",
    "    for i in range(0, len(paths), batch):\n",
    "        chunk = paths[i:i+batch]\n",
    "        imgs = []\n",
    "        for p in chunk:\n",
    "            im = Image.open(p).convert(\"RGB\")\n",
    "            imgs.append(tfm(im))\n",
    "        x = torch.stack(imgs, dim=0).to(DEVICE) if imgs else torch.empty(0)\n",
    "        if x.numel() == 0:\n",
    "            continue\n",
    "        feat = emb_net(x)              # (B,512,1,1)\n",
    "        feat = feat.view(feat.size(0), -1).cpu().numpy()\n",
    "        vecs.append(feat)\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros((0,512), dtype=np.float32)\n",
    "    return np.vstack(vecs).astype(np.float32)\n",
    "\n",
    "def save_confusion(y_true, y_pred, out_path, title=\"Confusion matrix\"):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=[\"sano(0)\",\"infectado(1)\"])\n",
    "    fig, ax = plt.subplots(figsize=(4.8,4.8))\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\", colorbar=False)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout(); plt.savefig(out_path, dpi=160); plt.close()\n",
    "\n",
    "def rnorm(x):\n",
    "    p1, p99 = np.percentile(x, 1), np.percentile(x, 99)\n",
    "    return np.clip((x - p1) / (p99 - p1 + 1e-8), 0, 1)\n",
    "\n",
    "# ------------------- Embeddings -------------------\n",
    "def build_or_load_embeddings():\n",
    "    emb_net, tfm = build_model_resnet18()\n",
    "\n",
    "    train_paths = list_images(DIR_TRAIN_SANOS)\n",
    "    val_sanos_paths = list_images(DIR_VAL_SANOS)\n",
    "    val_infs_paths  = list_images(DIR_VAL_INFECT)\n",
    "\n",
    "    ensure_non_empty(train_paths, f\"No hay imágenes en {DIR_TRAIN_SANOS}\")\n",
    "    ensure_non_empty(val_sanos_paths, f\"No hay imágenes en {DIR_VAL_SANOS}\")\n",
    "    ensure_non_empty(val_infs_paths,  f\"No hay imágenes en {DIR_VAL_INFECT}\")\n",
    "\n",
    "    if CACHE_TRAIN_EMB.exists():\n",
    "        X_train = np.load(CACHE_TRAIN_EMB)\n",
    "        print(f\"[CACHE] X_train sanos -> {X_train.shape}\")\n",
    "    else:\n",
    "        print(f\"[EMB] Extrayendo embeddings TRAIN sanos: {len(train_paths)}\")\n",
    "        X_train = embeddings_from_paths(train_paths, emb_net, tfm)\n",
    "        np.save(CACHE_TRAIN_EMB, X_train)\n",
    "\n",
    "    if CACHE_VALS_EMB.exists() and CACHE_VALI_EMB.exists():\n",
    "        X_vs = np.load(CACHE_VALS_EMB)\n",
    "        X_vi = np.load(CACHE_VALI_EMB)\n",
    "        print(f\"[CACHE] X_val sanos -> {X_vs.shape} | X_val infectados -> {X_vi.shape}\")\n",
    "    else:\n",
    "        print(\"[EMB] Extrayendo embeddings VALIDACIÓN…\")\n",
    "        X_vs = embeddings_from_paths(val_sanos_paths, emb_net, tfm)\n",
    "        X_vi = embeddings_from_paths(val_infs_paths, emb_net, tfm)\n",
    "        np.save(CACHE_VALS_EMB, X_vs)\n",
    "        np.save(CACHE_VALI_EMB, X_vi)\n",
    "\n",
    "    return X_train, (X_vs, X_vi), (val_sanos_paths, val_infs_paths)\n",
    "\n",
    "\n",
    "def make_pca_safe(ncomp, X_train):\n",
    "    # máximo = min(n_samples, n_features)\n",
    "    max_comp = min(X_train.shape[0], X_train.shape[1])\n",
    "    return min(ncomp, max_comp)\n",
    "\n",
    "# ------------------- Grid Search (AUC) -------------------\n",
    "def grid_search_auc(X_train, X_vs, X_vi):\n",
    "    best = {\"auc\": -1, \"pipe\": None, \"params\": None}\n",
    "    for ncomp in GRID_PCA:\n",
    "        for nu in GRID_NU:\n",
    "            for gamma in GRID_GAM:\n",
    "                ncomp_safe = make_pca_safe(ncomp, X_train)\n",
    "                pipe = Pipeline([\n",
    "                    (\"l2\", Normalizer(norm=\"l2\")),\n",
    "                    (\"sc\", StandardScaler()),            # centra y escala embeddings L2\n",
    "                    (\"pca\", PCA(n_components=ncomp_safe, whiten=True, random_state=42)),\n",
    "                    #(\"pca\", PCA(n_components=128, whiten=True, random_state=42)),\n",
    "                    (\"oc\", OneClassSVM(kernel=\"rbf\", nu=nu, gamma=gamma)),\n",
    "                ])\n",
    "                pipe.fit(X_train)  # SOLO sanos\n",
    "\n",
    "                # decision_function: mayor = más “normal”\n",
    "                s_sanos = pipe.score_samples(X_vs)  # igual que decision_function para OCSVM\n",
    "                s_infs  = pipe.score_samples(X_vi)\n",
    "                y_true  = np.r_[np.zeros_like(s_sanos), np.ones_like(s_infs)]\n",
    "                # anomaly_score = -decision_function (mayor = más anómalo)\n",
    "                scores  = -np.r_[s_sanos, s_infs]\n",
    "                try:\n",
    "                    auc = roc_auc_score(y_true, scores)\n",
    "                except Exception:\n",
    "                    auc = 0.5\n",
    "                print(f\"[GRID] PCA={ncomp:>3} nu={nu:<4} gamma={str(gamma):<7} | AUC={auc:.3f}\")\n",
    "                if auc > best[\"auc\"]:\n",
    "                    best.update({\"auc\": float(auc), \"pipe\": pipe,\n",
    "                                 \"params\": {\"pca\": ncomp, \"nu\": nu, \"gamma\": gamma}})\n",
    "    print(f\"[BEST] AUC={best['auc']:.3f} con params={best['params']}\")\n",
    "    return best[\"pipe\"], best[\"params\"], best[\"auc\"]\n",
    "\n",
    "# ------------------- Umbrales y métricas -------------------\n",
    "def pick_threshold(scores_sanos, scores_infs):\n",
    "    \"\"\"\n",
    "    scores_* son decision_function (mayor = más normal).\n",
    "    Retorna:\n",
    "      - thr_fpr: umbral por FPR objetivo en sanos (conservador)\n",
    "      - thr_f1:  umbral que maximiza F1 en validación\n",
    "    \"\"\"\n",
    "    thr_fpr = float(np.quantile(scores_sanos, FPR_TARGET))\n",
    "    vals = np.sort(np.unique(np.r_[scores_sanos, scores_infs]))\n",
    "    mids = (vals[1:]+vals[:-1])/2.0 if len(vals)>1 else np.array([vals[0]+1e-8])\n",
    "    best_f1, thr_f1 = -1, thr_fpr\n",
    "    y_true = np.r_[np.zeros_like(scores_sanos), np.ones_like(scores_infs)]\n",
    "    for thr in np.r_[thr_fpr, mids]:\n",
    "        y_pred = (np.r_[scores_sanos, scores_infs] < thr).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, thr_f1 = f1, float(thr)\n",
    "    return thr_fpr, thr_f1, best_f1\n",
    "\n",
    "def evaluate_and_plot(pipe, X_vs, X_vi, val_paths, thr_used, out_dir: Path):\n",
    "    (paths_s, paths_i) = val_paths\n",
    "    # decision_function: mayor = más normal\n",
    "    s_sanos = pipe.score_samples(X_vs)\n",
    "    s_infs  = pipe.score_samples(X_vi)\n",
    "    y_true  = np.r_[np.zeros_like(s_sanos), np.ones_like(s_infs)].astype(int)\n",
    "    decfun  = np.r_[s_sanos, s_infs]\n",
    "    anomaly = -decfun\n",
    "\n",
    "    # pred con umbral\n",
    "    y_pred = (decfun < thr_used).astype(int)\n",
    "\n",
    "    # métricas\n",
    "    metrics = {\n",
    "        \"threshold_used\": float(thr_used),\n",
    "        \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred)),\n",
    "        \"auc\": float(roc_auc_score(y_true, anomaly)),\n",
    "        \"average_precision\": float(average_precision_score(y_true, anomaly))\n",
    "    }\n",
    "\n",
    "    # CSV de resultados\n",
    "    import pandas as pd\n",
    "    rows = []\n",
    "    for p, sc in zip(paths_s, s_sanos):\n",
    "        rows.append((p.name, \"sano\", 0, float(sc)))\n",
    "    for p, sc in zip(paths_i, s_infs):\n",
    "        rows.append((p.name, \"no_sano\", 1, float(sc)))\n",
    "    df = pd.DataFrame(rows, columns=[\"image\",\"set\",\"y_true\",\"decision_function\"])\n",
    "    df[\"anomaly_score\"] = -df[\"decision_function\"]\n",
    "    df[\"y_pred\"] = (df[\"decision_function\"] < thr_used).astype(int)\n",
    "    df[\"correct\"] = (df[\"y_pred\"] == df[\"y_true\"]).astype(int)\n",
    "    df.to_csv(VAL_CSV, index=False)\n",
    "\n",
    "    # Gráficas\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_true, anomaly)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"AUC={metrics['auc']:.3f}\")\n",
    "    plt.plot([0,1],[0,1],\"--\",lw=1)\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (validation)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.savefig(out_dir/\"val_roc.png\", dpi=160); plt.close()\n",
    "    # PR\n",
    "    prec, rec, _ = precision_recall_curve(y_true, anomaly)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(rec, prec, lw=2, label=f\"AP={metrics['average_precision']:.3f}\")\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"PR (validation)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.savefig(out_dir/\"val_pr.png\", dpi=160); plt.close()\n",
    "    # Hist con línea de umbral (en decision_function)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(s_sanos, bins=30, alpha=0.6, label=\"sanos\")\n",
    "    plt.hist(s_infs,  bins=30, alpha=0.6, label=\"no_sanos\")\n",
    "    plt.axvline(thr_used, color=\"k\", ls=\"--\", lw=1.5, label=f\"thr={thr_used:.4f}\")\n",
    "    plt.xlabel(\"decision_function (mayor = más sano)\")\n",
    "    plt.ylabel(\"count\"); plt.title(\"Distribución decision_function (val)\")\n",
    "    plt.legend(); plt.tight_layout(); plt.savefig(out_dir/\"val_hist_decfun.png\", dpi=160); plt.close()\n",
    "    # CM\n",
    "    save_confusion(y_true, y_pred, out_dir/\"val_cm.png\", \"Matriz de confusión (val)\")\n",
    "\n",
    "    # Guardar métricas\n",
    "    with open(METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    # Resumen\n",
    "    print(\"\\n[MÉTRICAS VALIDACIÓN]\")\n",
    "    for k,v in metrics.items():\n",
    "        print(f\"- {k}: {v:.4f}\" if isinstance(v,float) else f\"- {k}: {v}\")\n",
    "    return metrics\n",
    "\n",
    "# ------------------- Main -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"[INFO] Device: {DEVICE}\")\n",
    "    # 1) Embeddings\n",
    "    X_train, (X_vs, X_vi), val_paths = build_or_load_embeddings()\n",
    "    print(f\"[SHAPE] X_train={X_train.shape} | X_val_sanos={X_vs.shape} | X_val_infectados={X_vi.shape}\")\n",
    "\n",
    "    # 2) Grid Search por AUC\n",
    "    pipe, params, best_auc = grid_search_auc(X_train, X_vs, X_vi)\n",
    "\n",
    "    # 3) Umbrales\n",
    "    s_sanos = pipe.score_samples(X_vs)\n",
    "    s_infs  = pipe.score_samples(X_vi)\n",
    "    thr_fpr, thr_f1, best_f1 = pick_threshold(s_sanos, s_infs)\n",
    "    print(f\"[THR] FPR target {int(FPR_TARGET*100)}% -> {thr_fpr:.6f}\")\n",
    "    print(f\"[THR] Mejor F1 en validación -> {thr_f1:.6f} (F1={best_f1:.3f})\")\n",
    "\n",
    "    # 4) Evaluar y graficar (usar F1 por defecto; cambia a thr_fpr si quieres conservador)\n",
    "    thr_used = thr_f1\n",
    "    metrics = evaluate_and_plot(pipe, X_vs, X_vi, val_paths, thr_used, OUT_DIR)\n",
    "\n",
    "    # 5) Guardar pipeline y umbral\n",
    "    joblib.dump({\"pipeline\": pipe, \"params\": params, \"thr_used\": float(thr_used),\n",
    "                 \"cnn\": \"resnet18\", \"img_size\": IMG_SIZE},\n",
    "                MODEL_PATH)\n",
    "    print(f\"[OK] Guardado: {MODEL_PATH}\\nArtefactos en {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c2c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
